{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env: scGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "from types import MethodType\n",
    "import importlib\n",
    "from scperturb import *\n",
    "\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "\n",
    "import celloracle as co\n",
    "co.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/data1/lichen/code/single_cell_perturbation/scPerturb/Byte_Pert_Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v1\n",
    "from v1.utils import *\n",
    "from v1.dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'v1.dataloader' from '/data1/lichen/code/single_cell_perturbation/scPerturb/Byte_Pert_Data/v1/dataloader.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(v1)\n",
    "importlib.reload(v1.utils)\n",
    "importlib.reload(v1.dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1000运行CellOracle-非并行版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 36720 × 978\n",
       "    obs: 'sig_id', 'pert_id', 'pert_iname', 'pert_type', 'cell_id', 'pert_dose', 'pert_dose_unit', 'pert_idose', 'pert_time', 'pert_time_unit', 'pert_itime', 'distil_id'\n",
       "    var: 'pr_gene_id', 'pr_gene_symbol', 'pr_gene_title', 'pr_is_lm', 'pr_is_bing'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - get cell line name\n",
    "common_cell_line = \\\n",
    "{   'A549': 'A549',\n",
    "    'HEPG2': 'HepG2',\n",
    "    'HT29': 'HT29',\n",
    "    'MCF7': 'MCF7',\n",
    "    # 'SKBR3': 'SK-BR-3',\n",
    "    'SW480': 'SW480',\n",
    "    'PC3': 'PC3',\n",
    "    'A375': 'A375',\n",
    "} # L1000 cell line : single-cell cell line\n",
    "\n",
    "# - read adata_L1000, this is processed data\n",
    "adata_L1000 = sc.read('/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/GSE92742/adata_gene_pert.h5ad')\n",
    "adata_L1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== cell line is A549\n",
      "adata.shape is:  (500, 5155)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c385519c4d934e589544222e44aec4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3620\n",
      "common_perts num:  306\n",
      "common var to L1000 data is:  933\n",
      "5155 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n",
      "  0%|          | 0/306 [00:00<?, ?it/s]... storing 'celltype' as categorical\n",
      "... storing 'batch' as categorical\n",
      "  0%|          | 0/306 [01:14<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "for cell_line_bulk in list(common_cell_line.keys())[:]:\n",
    "    cell_line_single = common_cell_line[cell_line_bulk]\n",
    "    print('='*20, f'cell line is {cell_line_single}')\n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "    #===================prepare data\n",
    "    if cell_line_bulk in ['PC3', 'A375']:\n",
    "        save_dir_adata = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/single_cell_data/SCP542'\n",
    "    else:\n",
    "        save_dir_adata = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/single_cell_data/CNP0003658'\n",
    "    adata_rna = sc.read(os.path.join(save_dir_adata, cell_line_bulk, f'adata_{cell_line_bulk}.h5ad'))\n",
    "\n",
    "    # - consctrut corr mtx\n",
    "    if not isinstance(adata_rna.X, np.ndarray):\n",
    "        adata_rna.X = adata_rna.X.toarray()\n",
    "    # corr_mtx = np.corrcoef(adata_rna.X.T)\n",
    "    \n",
    "    # - get var_names\n",
    "    var_names = list(adata_rna.var_names)\n",
    "    \n",
    "    # - get common pert\n",
    "    adata_L1000_sub = adata_L1000[adata_L1000.obs['cell_id']==cell_line_bulk]\n",
    "    L1000_total_perts = np.unique(adata_L1000_sub.obs['pert_iname'])\n",
    "    \n",
    "    \n",
    "    n_cells_downsample = 10000\n",
    "    threshold_number = 10000\n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    # - get control adata\n",
    "    adata = adata_rna.copy()\n",
    "    adata.obs['celltype'] = cell_line_bulk\n",
    "    print(f'adata.shape is: ',adata.shape)\n",
    "\n",
    "    # -- get the baseGRN\n",
    "    # Load TF info which was made from mouse cell atlas dataset.\n",
    "    base_GRN = co.data.load_human_promoter_base_GRN()\n",
    "    print('base_GRN.shape: ', base_GRN.shape)\n",
    "\n",
    "    tmp_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/L1000'\n",
    "    save_prefix = f'CellOracle/{cell_line_bulk}' # use result of K562 to do the direct transfer\n",
    "    os.makedirs(os.path.join(tmp_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "    save_dir = os.path.join(tmp_dir, save_prefix)\n",
    "    if os.path.exists(os.path.join(save_dir, \"ctrl.celloracle.oracle\")):\n",
    "        print('file exists')\n",
    "        oracle = co.load_hdf5(os.path.join(save_dir, \"ctrl.celloracle.oracle\"))\n",
    "        links = co.load_hdf5(file_path=os.path.join(save_dir, \"ctrl.celloracle.links\"))\n",
    "        \n",
    "    else:\n",
    "\n",
    "        # - start CellOracle process for the whole ctrl\n",
    "\n",
    "        # -- keep raw cont data before log transformation\n",
    "        adata.raw = adata\n",
    "        if not isinstance(adata.raw.X, np.ndarray):\n",
    "            adata.layers[\"raw_count\"] = (np.exp(adata.raw.X.toarray())-1).copy()\n",
    "        else:\n",
    "            adata.layers[\"raw_count\"] = (np.exp(adata.raw.X)-1).copy()\n",
    "            \n",
    "        # -- get umap \n",
    "        sc.pp.scale(adata)\n",
    "        # PCA\n",
    "        sc.tl.pca(adata, svd_solver='arpack', random_state=2022)\n",
    "        # UMAP\n",
    "        sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20, random_state=2022)\n",
    "        sc.tl.umap(adata,random_state=2022)\n",
    "\n",
    "        # -- Random downsampling into 30K cells if the anndata object include more than 30 K cells.\n",
    "        if adata.shape[0] > n_cells_downsample:\n",
    "            # Let's dowmsample into 30K cells\n",
    "            sc.pp.subsample(adata, n_obs=n_cells_downsample, random_state=123)\n",
    "        print(f\"Cell number is :{adata.shape[0]}\")\n",
    "\n",
    "        # -- Instantiate Oracle object\n",
    "        oracle = co.Oracle()\n",
    "\n",
    "        # -- Check data in anndata\n",
    "        print(\"Metadata columns :\", list(adata.obs.columns))\n",
    "        print(\"Dimensional reduction: \", list(adata.obsm.keys()))\n",
    "\n",
    "        # -- In this notebook, we use the unscaled mRNA count for the nput of Oracle object.\n",
    "        adata.X = adata.layers[\"raw_count\"].copy()\n",
    "\n",
    "        # -- Instantiate Oracle object.\n",
    "        oracle.import_anndata_as_raw_count(adata=adata,\n",
    "                                        cluster_column_name=\"celltype\",\n",
    "                                        embedding_name=\"X_umap\")\n",
    "\n",
    "        # -- You can load TF info dataframe with the following code.\n",
    "        oracle.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "        # -- knn imputation, this step is needed for the whole ctrl\n",
    "        # Perform PCA\n",
    "        oracle.perform_PCA()\n",
    "\n",
    "        # Select important PCs\n",
    "        plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])\n",
    "        n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]\n",
    "        plt.axvline(n_comps, c=\"k\")\n",
    "        plt.show()\n",
    "        print(n_comps)\n",
    "        n_comps = min(n_comps, 50)\n",
    "\n",
    "        n_cell = oracle.adata.shape[0]\n",
    "        print(f\"cell number is :{n_cell}\")\n",
    "\n",
    "        k = int(0.025*n_cell)\n",
    "        print(f\"Auto-selected k is :{k}\")\n",
    "\n",
    "        oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,\n",
    "                            b_maxl=k*4, n_jobs=4)\n",
    "\n",
    "        # model_prefix = ''\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        # -- save the oracle\n",
    "        oracle.to_hdf5(os.path.join(save_dir, \"ctrl.celloracle.oracle\"))\n",
    "\n",
    "        # -- get the links\n",
    "        # Calculate GRN for each population in \"louvain_annot\" clustering unit.\n",
    "        # This step may take some time.(~30 minutes)\n",
    "        links = oracle.get_links(cluster_name_for_GRN_unit=\"celltype\", alpha=10,\n",
    "                                verbose_level=10)\n",
    "\n",
    "        # -- Save Links object.\n",
    "        links.to_hdf5(file_path=os.path.join(save_dir, \"ctrl.celloracle.links\"))\n",
    "\n",
    "\n",
    "    # -- filter and get the coef_mtx\n",
    "    links.filter_links(threshold_number=threshold_number,\n",
    "                        p=0.001,\n",
    "                        weight='coef_abs')\n",
    "    oracle.get_cluster_specific_TFdict_from_Links(links_object=links)\n",
    "    oracle.fit_GRN_for_simulation(alpha=10,\n",
    "                                use_cluster_specific_TFdict=True)\n",
    "    \n",
    "    ###################################################\n",
    "    # - get all the TFs in the base_GRN\n",
    "    TFdict = import_TF_data(TF_info_matrix=base_GRN)\n",
    "    tf_target_dict = {}\n",
    "    for target, gene_set in TFdict.items():\n",
    "        for tf in gene_set:\n",
    "            if tf not in tf_target_dict:\n",
    "                tf_target_dict[tf] = []\n",
    "                tf_target_dict[tf].append(target)\n",
    "            else:\n",
    "                tf_target_dict[tf].append(target)\n",
    "    total_tf_list = list(tf_target_dict.keys())\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #####################################################\n",
    "    var_names = list(adata.var_names)    \n",
    "    single_total_perts = np.intersect1d(total_tf_list, adata.var_names)\n",
    "    common_perts = np.intersect1d(single_total_perts, L1000_total_perts)\n",
    "    print('L1000_total_perts num: ', len(L1000_total_perts))\n",
    "    print('common_perts num: ', len(common_perts))\n",
    "    print('common var to L1000 data is: ', len(np.intersect1d(var_names, adata_L1000.var_names)))\n",
    "\n",
    "    ###########################################\n",
    "    celltype = adata.obs['celltype'].unique()[0]\n",
    "\n",
    "    # - get the tf_GRN_dict, to check whether pert have regulatory relations\n",
    "    gene_GRN_mtx = oracle.coef_matrix_per_cluster[celltype].copy()\n",
    "    tf_GRN_mtx = gene_GRN_mtx[~(gene_GRN_mtx == 0).all(axis=1)]\n",
    "    # - get TF-target pair and the regulatory values\n",
    "    tf_GRN_dict = {} # the tf to targets\n",
    "    for i in range(len(tf_GRN_mtx)):\n",
    "        tmp = tf_GRN_mtx.iloc[i,:]\n",
    "        tmp = tmp[tmp!=0]\n",
    "\n",
    "        tf_GRN_dict[tf_GRN_mtx.index[i]] = {}\n",
    "        for j in range(len(tmp)):\n",
    "            tf_GRN_dict[tf_GRN_mtx.index[i]][tmp.index[j]] = tmp.values[j]\n",
    "\n",
    "    ###########################################        \n",
    "    # - get oracle_ctrl\n",
    "    adata_rna.obs['celltype'] = cell_line_bulk\n",
    "    adata_ctrl = adata_rna.copy()\n",
    "    # keep raw cont data before log transformation\n",
    "    adata_ctrl.raw = adata_ctrl\n",
    "\n",
    "    # the result will be recovered in normalized_count\n",
    "    if not isinstance(adata_ctrl.raw.X, np.ndarray):\n",
    "        adata_ctrl.layers[\"raw_count\"] = (np.exp(adata_ctrl.raw.X.toarray())-1).copy()\n",
    "    else:\n",
    "        adata_ctrl.layers[\"raw_count\"] = (np.exp(adata_ctrl.raw.X)-1).copy()\n",
    "        \n",
    "    sc.pp.scale(adata_ctrl)\n",
    "    # PCA\n",
    "    sc.tl.pca(adata_ctrl, svd_solver='arpack', random_state=2022)\n",
    "\n",
    "    # Diffusion map\n",
    "    sc.pp.neighbors(adata_ctrl, n_neighbors=4, n_pcs=20, random_state=2022)\n",
    "    sc.tl.umap(adata_ctrl,random_state=2022)\n",
    "\n",
    "    # Instantiate Oracle object\n",
    "    oracle_ctrl = co.Oracle()\n",
    "\n",
    "    # In this notebook, we use the unscaled mRNA count for the nput of Oracle object.\n",
    "    adata_ctrl.X = adata_ctrl.layers[\"raw_count\"].copy()\n",
    "\n",
    "    # Instantiate Oracle object.\n",
    "    oracle_ctrl.import_anndata_as_raw_count(adata=adata_ctrl,\n",
    "                                    cluster_column_name=\"celltype\",\n",
    "                                    embedding_name=\"X_umap\")\n",
    "\n",
    "    # You can load TF info dataframe with the following code.\n",
    "    oracle_ctrl.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "    # get the imputed_count, here we dont do the impute to get the prediction\n",
    "    oracle_ctrl.adata.layers[\"imputed_count\"] = oracle_ctrl.adata.layers[\"normalized_count\"].copy()\n",
    "\n",
    "    # get the coef from the whole ctrl\n",
    "    oracle_ctrl.coef_matrix_per_cluster = oracle.coef_matrix_per_cluster\n",
    "    \n",
    "    pert_gene_rank_dict = {} \n",
    "    for pert in tqdm(common_perts):\n",
    "        \n",
    "\n",
    "        # - this is for crispra\n",
    "        gois = [pert]\n",
    "        goi_dict = {}\n",
    "\n",
    "        # - all data in L1000 is knockdown\n",
    "        for goi in gois:\n",
    "            # -- if original value is zero\n",
    "            if np.mean(adata_rna[:,goi].X.toarray())==0:\n",
    "                print(f'{goi} ctrl expression is 0')\n",
    "                continue\n",
    "            # -- if the TF has no targets\n",
    "            if goi not in list(tf_GRN_dict.keys()):\n",
    "                print(f'{goi} is not in the tf_GRN_dict, no targets')\n",
    "                continue\n",
    "            goi_dict[goi] = 0\n",
    "        if len(goi_dict) == 0:\n",
    "            print(f'{pert} is filtered')\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Enter perturbation conditions to simulate signal propagation after the perturbation.\n",
    "        oracle_ctrl.simulate_shift(perturb_condition=goi_dict,\n",
    "                            n_propagation=3)\n",
    "        # - get the prediction; delta_X = simulated_count - imputed_count\n",
    "        delta_X, simulated_count = oracle_ctrl.adata.layers[\"delta_X\"], oracle_ctrl.adata.layers[\"simulated_count\"]\n",
    "\n",
    "\n",
    "        # - create adata_pert\n",
    "        adata_pert = adata_rna.copy()\n",
    "        adata_pert.X = simulated_count\n",
    "        adata_pert.X[adata_pert.X < 0] = 0\n",
    "        adata_pert.obs_names = [i+f'_{pert}' for i in adata_pert.obs_names]\n",
    "\n",
    "        # - adata_ctrl\n",
    "        adata_ctrl = adata_rna.copy()\n",
    "\n",
    "        adata_ctrl.obs['batch'] = 'ctrl'\n",
    "        adata_pert.obs['batch'] = 'pert'\n",
    "\n",
    "        adata_concat = ad.concat([adata_ctrl, adata_pert])\n",
    "        adata_concat.obs['batch'] = adata_concat.obs['batch'].astype('category') \n",
    "        adata_concat.obs['celltype'] = adata_concat.obs['celltype'].astype('category') \n",
    "\n",
    "        # - cal de genes\n",
    "        rankby_abs = False\n",
    "\n",
    "        sc.tl.rank_genes_groups(\n",
    "            adata_concat,\n",
    "            groupby='batch',\n",
    "            reference='ctrl',\n",
    "            rankby_abs=rankby_abs,\n",
    "            n_genes=len(adata_concat.var),\n",
    "            use_raw=False,\n",
    "            method = 'wilcoxon'\n",
    "        )\n",
    "        de_genes = pd.DataFrame(adata_concat.uns['rank_genes_groups']['names'])\n",
    "        pvals = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals'])\n",
    "        pvals_adj = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals_adj'])\n",
    "        scores = pd.DataFrame(adata_concat.uns['rank_genes_groups']['scores'])\n",
    "        logfoldchanges = pd.DataFrame(adata_concat.uns['rank_genes_groups']['logfoldchanges'])\n",
    "\n",
    "        # - get gene_score\n",
    "        gene_score = pd.DataFrame({'gene':list(de_genes['pert']),\n",
    "                                    'z-score':list(scores['pert'])})\n",
    "\n",
    "        pert_gene_rank_dict[pert] = (list(de_genes['pert']), list(scores['pert']))\n",
    "        \n",
    "        break\n",
    "        \n",
    "    save_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark_202410/zero_shot/result'\n",
    "    save_prefix = f'CellOracle/{cell_line_bulk}' # use result of K562 to do the direct transfer\n",
    "    os.makedirs(os.path.join(save_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "    import json\n",
    "    with open(os.path.join(save_dir, save_prefix, 'pert_gene_rank_dict.json'), 'w') as f:\n",
    "        json.dump(pert_gene_rank_dict, f)\n",
    "        \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1000运行CellOracle-并行版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== cell line is A549\n",
      "adata.shape is:  (500, 5155)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "==================== cell line is HepG2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "====================adata.shape is:   cell line is HT29(500, 5032)\n",
      "\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (500, 5141)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "==================== cell line is MCF7\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (409, 5450)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "\n",
      "==================== cell line is SW480\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists==================== cell line is PC3\n",
      "adata.shape is:  (169, 5417)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "adata.shape is:  (500, 3687)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "==================== cell line is A375\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (500, 5379)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d455f3a28439441384b09458ff907bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86895edf86134bd98699d679874c49dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcb742b2f944020bfaf531bc9c9432b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4ffb2115c542d1b99ef6d53db1d3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f249f8dd724e497d841da74adf689df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190f11efd69b4f6b8b7ee0b4ad88cf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0bca3fe3b34a86974188405a809d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3620\n",
      "common_perts num:  306\n",
      "common var to L1000 data is:  933\n",
      "L1000_total_perts num:  232\n",
      "common_perts num:  35\n",
      "common var to L1000 data is:  932\n",
      "L1000_total_perts num:  3341\n",
      "common_perts num:  252\n",
      "common var to L1000 data is:  915\n",
      "5155 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3780\n",
      "common_perts num:  278\n",
      "common var to L1000 data is:  932\n",
      "L1000_total_perts num:  3669\n",
      "common_perts num:  291\n",
      "common var to L1000 data is:  945\n",
      "5032 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3302\n",
      "common_perts num:  259\n",
      "common var to L1000 data is:  931\n",
      "5417 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5379 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3649\n",
      "common_perts num:  280\n",
      "common var to L1000 data is:  930\n",
      "5141 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5450 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n",
      "  0%|          | 0/280 [00:00<?, ?it/s]... storing 'x' as categorical\n",
      "  3%|▎         | 1/35 [01:03<35:43, 63.05s/it]it]... storing 'x' as categorical\n",
      "  1%|          | 2/278 [01:07<2:32:51, 33.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHGEF12 is not in the tf_GRN_dict, no targets\n",
      "ARHGEF12 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/259 [01:18<5:38:40, 78.76s/it]... storing 'x' as categorical\n",
      "  0%|          | 1/291 [01:22<6:38:05, 82.37s/it]... storing 'x' as categorical\n",
      "  1%|▏         | 4/278 [01:38<1:40:45, 22.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARID5B is not in the tf_GRN_dict, no targets\n",
      "ARID5B is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/280 [01:40<7:49:00, 100.86s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from scipy.spatial.distance import cdist\n",
    "import concurrent.futures\n",
    "import json\n",
    "\n",
    "# 定义处理每个 cell_line_single 的函数\n",
    "def process_cell_line(cell_line_bulk, cell_line_single, common_cell_line, adata_L1000):\n",
    "    print('=' * 20, f'cell line is {cell_line_single}')\n",
    "\n",
    "    #===================prepare data\n",
    "    if cell_line_bulk in ['PC3', 'A375']:\n",
    "        save_dir_adata = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/single_cell_data/SCP542'\n",
    "    else:\n",
    "        save_dir_adata = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/single_cell_data/CNP0003658'\n",
    "    adata_rna = sc.read(os.path.join(save_dir_adata, cell_line_bulk, f'adata_{cell_line_bulk}.h5ad'))\n",
    "\n",
    "    # - consctrut corr mtx\n",
    "    if not isinstance(adata_rna.X, np.ndarray):\n",
    "        adata_rna.X = adata_rna.X.toarray()\n",
    "    # corr_mtx = np.corrcoef(adata_rna.X.T)\n",
    "    \n",
    "    # - get var_names\n",
    "    var_names = list(adata_rna.var_names)\n",
    "    \n",
    "    # - get common pert\n",
    "    adata_L1000_sub = adata_L1000[adata_L1000.obs['cell_id']==cell_line_bulk]\n",
    "    L1000_total_perts = np.unique(adata_L1000_sub.obs['pert_iname'])\n",
    "    \n",
    "    \n",
    "    n_cells_downsample = 10000\n",
    "    threshold_number = 10000\n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    # - get control adata\n",
    "    adata = adata_rna.copy()\n",
    "    adata.obs['celltype'] = cell_line_bulk\n",
    "    print(f'adata.shape is: ',adata.shape)\n",
    "\n",
    "    # -- get the baseGRN\n",
    "    # Load TF info which was made from mouse cell atlas dataset.\n",
    "    base_GRN = co.data.load_human_promoter_base_GRN()\n",
    "    print('base_GRN.shape: ', base_GRN.shape)\n",
    "\n",
    "    tmp_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/L1000'\n",
    "    save_prefix = f'CellOracle/{cell_line_bulk}' # use result of K562 to do the direct transfer\n",
    "    os.makedirs(os.path.join(tmp_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "    save_dir = os.path.join(tmp_dir, save_prefix)\n",
    "    if os.path.exists(os.path.join(save_dir, \"ctrl.celloracle.oracle\")):\n",
    "        print('file exists')\n",
    "        oracle = co.load_hdf5(os.path.join(save_dir, \"ctrl.celloracle.oracle\"))\n",
    "        links = co.load_hdf5(file_path=os.path.join(save_dir, \"ctrl.celloracle.links\"))\n",
    "        \n",
    "    else:\n",
    "\n",
    "        # - start CellOracle process for the whole ctrl\n",
    "\n",
    "        # -- keep raw cont data before log transformation\n",
    "        adata.raw = adata\n",
    "        if not isinstance(adata.raw.X, np.ndarray):\n",
    "            adata.layers[\"raw_count\"] = (np.exp(adata.raw.X.toarray())-1).copy()\n",
    "        else:\n",
    "            adata.layers[\"raw_count\"] = (np.exp(adata.raw.X)-1).copy()\n",
    "            \n",
    "        # -- get umap \n",
    "        sc.pp.scale(adata)\n",
    "        # PCA\n",
    "        sc.tl.pca(adata, svd_solver='arpack', random_state=2022)\n",
    "        # UMAP\n",
    "        sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20, random_state=2022)\n",
    "        sc.tl.umap(adata,random_state=2022)\n",
    "\n",
    "        # -- Random downsampling into 30K cells if the anndata object include more than 30 K cells.\n",
    "        if adata.shape[0] > n_cells_downsample:\n",
    "            # Let's dowmsample into 30K cells\n",
    "            sc.pp.subsample(adata, n_obs=n_cells_downsample, random_state=123)\n",
    "        print(f\"Cell number is :{adata.shape[0]}\")\n",
    "\n",
    "        # -- Instantiate Oracle object\n",
    "        oracle = co.Oracle()\n",
    "\n",
    "        # -- Check data in anndata\n",
    "        print(\"Metadata columns :\", list(adata.obs.columns))\n",
    "        print(\"Dimensional reduction: \", list(adata.obsm.keys()))\n",
    "\n",
    "        # -- In this notebook, we use the unscaled mRNA count for the nput of Oracle object.\n",
    "        adata.X = adata.layers[\"raw_count\"].copy()\n",
    "\n",
    "        # -- Instantiate Oracle object.\n",
    "        oracle.import_anndata_as_raw_count(adata=adata,\n",
    "                                        cluster_column_name=\"celltype\",\n",
    "                                        embedding_name=\"X_umap\")\n",
    "\n",
    "        # -- You can load TF info dataframe with the following code.\n",
    "        oracle.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "        # -- knn imputation, this step is needed for the whole ctrl\n",
    "        # Perform PCA\n",
    "        oracle.perform_PCA()\n",
    "\n",
    "        # Select important PCs\n",
    "        plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])\n",
    "        n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]\n",
    "        plt.axvline(n_comps, c=\"k\")\n",
    "        plt.show()\n",
    "        print(n_comps)\n",
    "        n_comps = min(n_comps, 50)\n",
    "\n",
    "        n_cell = oracle.adata.shape[0]\n",
    "        print(f\"cell number is :{n_cell}\")\n",
    "\n",
    "        k = int(0.025*n_cell)\n",
    "        print(f\"Auto-selected k is :{k}\")\n",
    "\n",
    "        oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,\n",
    "                            b_maxl=k*4, n_jobs=4)\n",
    "\n",
    "        # model_prefix = ''\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        # -- save the oracle\n",
    "        oracle.to_hdf5(os.path.join(save_dir, \"ctrl.celloracle.oracle\"))\n",
    "\n",
    "        # -- get the links\n",
    "        # Calculate GRN for each population in \"louvain_annot\" clustering unit.\n",
    "        # This step may take some time.(~30 minutes)\n",
    "        links = oracle.get_links(cluster_name_for_GRN_unit=\"celltype\", alpha=10,\n",
    "                                verbose_level=10)\n",
    "\n",
    "        # -- Save Links object.\n",
    "        links.to_hdf5(file_path=os.path.join(save_dir, \"ctrl.celloracle.links\"))\n",
    "\n",
    "\n",
    "    # -- filter and get the coef_mtx\n",
    "    links.filter_links(threshold_number=threshold_number,\n",
    "                        p=0.001,\n",
    "                        weight='coef_abs')\n",
    "    oracle.get_cluster_specific_TFdict_from_Links(links_object=links)\n",
    "    oracle.fit_GRN_for_simulation(alpha=10,\n",
    "                                use_cluster_specific_TFdict=True)\n",
    "    \n",
    "    ###################################################\n",
    "    # - get all the TFs in the base_GRN\n",
    "    TFdict = import_TF_data(TF_info_matrix=base_GRN)\n",
    "    tf_target_dict = {}\n",
    "    for target, gene_set in TFdict.items():\n",
    "        for tf in gene_set:\n",
    "            if tf not in tf_target_dict:\n",
    "                tf_target_dict[tf] = []\n",
    "                tf_target_dict[tf].append(target)\n",
    "            else:\n",
    "                tf_target_dict[tf].append(target)\n",
    "    total_tf_list = list(tf_target_dict.keys())\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #####################################################\n",
    "    var_names = list(adata.var_names)    \n",
    "    single_total_perts = np.intersect1d(total_tf_list, adata.var_names)\n",
    "    common_perts = np.intersect1d(single_total_perts, L1000_total_perts)\n",
    "    print('L1000_total_perts num: ', len(L1000_total_perts))\n",
    "    print('common_perts num: ', len(common_perts))\n",
    "    print('common var to L1000 data is: ', len(np.intersect1d(var_names, adata_L1000.var_names)))\n",
    "\n",
    "    ###########################################\n",
    "    celltype = adata.obs['celltype'].unique()[0]\n",
    "\n",
    "    # - get the tf_GRN_dict, to check whether pert have regulatory relations\n",
    "    gene_GRN_mtx = oracle.coef_matrix_per_cluster[celltype].copy()\n",
    "    tf_GRN_mtx = gene_GRN_mtx[~(gene_GRN_mtx == 0).all(axis=1)]\n",
    "    # - get TF-target pair and the regulatory values\n",
    "    tf_GRN_dict = {} # the tf to targets\n",
    "    for i in range(len(tf_GRN_mtx)):\n",
    "        tmp = tf_GRN_mtx.iloc[i,:]\n",
    "        tmp = tmp[tmp!=0]\n",
    "\n",
    "        tf_GRN_dict[tf_GRN_mtx.index[i]] = {}\n",
    "        for j in range(len(tmp)):\n",
    "            tf_GRN_dict[tf_GRN_mtx.index[i]][tmp.index[j]] = tmp.values[j]\n",
    "\n",
    "    ###########################################        \n",
    "    # - get oracle_ctrl\n",
    "    adata_rna.obs['celltype'] = cell_line_bulk\n",
    "    adata_ctrl = adata_rna.copy()\n",
    "    # keep raw cont data before log transformation\n",
    "    adata_ctrl.raw = adata_ctrl\n",
    "\n",
    "    # the result will be recovered in normalized_count\n",
    "    if not isinstance(adata_ctrl.raw.X, np.ndarray):\n",
    "        adata_ctrl.layers[\"raw_count\"] = (np.exp(adata_ctrl.raw.X.toarray())-1).copy()\n",
    "    else:\n",
    "        adata_ctrl.layers[\"raw_count\"] = (np.exp(adata_ctrl.raw.X)-1).copy()\n",
    "        \n",
    "    sc.pp.scale(adata_ctrl)\n",
    "    # PCA\n",
    "    sc.tl.pca(adata_ctrl, svd_solver='arpack', random_state=2022)\n",
    "\n",
    "    # Diffusion map\n",
    "    sc.pp.neighbors(adata_ctrl, n_neighbors=4, n_pcs=20, random_state=2022)\n",
    "    sc.tl.umap(adata_ctrl,random_state=2022)\n",
    "\n",
    "    # Instantiate Oracle object\n",
    "    oracle_ctrl = co.Oracle()\n",
    "\n",
    "    # In this notebook, we use the unscaled mRNA count for the nput of Oracle object.\n",
    "    adata_ctrl.X = adata_ctrl.layers[\"raw_count\"].copy()\n",
    "\n",
    "    # Instantiate Oracle object.\n",
    "    oracle_ctrl.import_anndata_as_raw_count(adata=adata_ctrl,\n",
    "                                    cluster_column_name=\"celltype\",\n",
    "                                    embedding_name=\"X_umap\")\n",
    "\n",
    "    # You can load TF info dataframe with the following code.\n",
    "    oracle_ctrl.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "    # get the imputed_count, here we dont do the impute to get the prediction\n",
    "    oracle_ctrl.adata.layers[\"imputed_count\"] = oracle_ctrl.adata.layers[\"normalized_count\"].copy()\n",
    "\n",
    "    # get the coef from the whole ctrl\n",
    "    oracle_ctrl.coef_matrix_per_cluster = oracle.coef_matrix_per_cluster\n",
    "    \n",
    "    pert_gene_rank_dict = {} \n",
    "    for pert in tqdm(common_perts):\n",
    "        \n",
    "\n",
    "        # - this is for crispra\n",
    "        gois = [pert]\n",
    "        goi_dict = {}\n",
    "\n",
    "        # - all data in L1000 is knockdown\n",
    "        for goi in gois:\n",
    "            # -- if original value is zero\n",
    "            if np.mean(adata_rna[:,goi].X.toarray())==0:\n",
    "                print(f'{goi} ctrl expression is 0')\n",
    "                continue\n",
    "            # -- if the TF has no targets\n",
    "            if goi not in list(tf_GRN_dict.keys()):\n",
    "                print(f'{goi} is not in the tf_GRN_dict, no targets')\n",
    "                continue\n",
    "            goi_dict[goi] = 0\n",
    "        if len(goi_dict) == 0:\n",
    "            print(f'{pert} is filtered')\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Enter perturbation conditions to simulate signal propagation after the perturbation.\n",
    "        oracle_ctrl.simulate_shift(perturb_condition=goi_dict,\n",
    "                            n_propagation=3)\n",
    "        # - get the prediction; delta_X = simulated_count - imputed_count\n",
    "        delta_X, simulated_count = oracle_ctrl.adata.layers[\"delta_X\"], oracle_ctrl.adata.layers[\"simulated_count\"]\n",
    "\n",
    "\n",
    "        # - create adata_pert\n",
    "        adata_pert = adata_rna.copy()\n",
    "        adata_pert.X = simulated_count\n",
    "        adata_pert.X[adata_pert.X < 0] = 0\n",
    "        adata_pert.obs_names = [i+f'_{pert}' for i in adata_pert.obs_names]\n",
    "\n",
    "        # - adata_ctrl\n",
    "        adata_ctrl = adata_rna.copy()\n",
    "\n",
    "        adata_ctrl.obs['batch'] = 'ctrl'\n",
    "        adata_pert.obs['batch'] = 'pert'\n",
    "\n",
    "        adata_concat = ad.concat([adata_ctrl, adata_pert])\n",
    "        adata_concat.obs['batch'] = adata_concat.obs['batch'].astype('category') \n",
    "        adata_concat.obs['celltype'] = adata_concat.obs['celltype'].astype('category') \n",
    "\n",
    "        # - cal de genes\n",
    "        rankby_abs = False\n",
    "\n",
    "        sc.tl.rank_genes_groups(\n",
    "            adata_concat,\n",
    "            groupby='batch',\n",
    "            reference='ctrl',\n",
    "            rankby_abs=rankby_abs,\n",
    "            n_genes=len(adata_concat.var),\n",
    "            use_raw=False,\n",
    "            method = 'wilcoxon'\n",
    "        )\n",
    "        de_genes = pd.DataFrame(adata_concat.uns['rank_genes_groups']['names'])\n",
    "        pvals = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals'])\n",
    "        pvals_adj = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals_adj'])\n",
    "        scores = pd.DataFrame(adata_concat.uns['rank_genes_groups']['scores'])\n",
    "        logfoldchanges = pd.DataFrame(adata_concat.uns['rank_genes_groups']['logfoldchanges'])\n",
    "\n",
    "        # - get gene_score\n",
    "        gene_score = pd.DataFrame({'gene':list(de_genes['pert']),\n",
    "                                    'z-score':list(scores['pert'])})\n",
    "\n",
    "        pert_gene_rank_dict[pert] = (list(de_genes['pert']), list(scores['pert']))\n",
    "        \n",
    "        # break\n",
    "        \n",
    "    save_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark_202410/zero_shot/result'\n",
    "    save_prefix = f'CellOracle/{cell_line_bulk}' # use result of K562 to do the direct transfer\n",
    "    os.makedirs(os.path.join(save_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "    import json\n",
    "    with open(os.path.join(save_dir, save_prefix, 'pert_gene_rank_dict.json'), 'w') as f:\n",
    "        json.dump(pert_gene_rank_dict, f)\n",
    "        \n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    # - get cell line name\n",
    "    common_cell_line = \\\n",
    "    {   'A549': 'A549',\n",
    "        'HEPG2': 'HepG2',\n",
    "        'HT29': 'HT29',\n",
    "        'MCF7': 'MCF7',\n",
    "        # 'SKBR3': 'SK-BR-3',\n",
    "        'SW480': 'SW480',\n",
    "        'PC3': 'PC3',\n",
    "        'A375': 'A375',\n",
    "    } # L1000 cell line : single-cell cell line\n",
    "\n",
    "    # - read adata_L1000, this is processed data\n",
    "    adata_L1000 = sc.read('/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/GSE92742/adata_gene_pert.h5ad')\n",
    "\n",
    "\n",
    "    # 使用并行执行\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_cell_line, cell_line_bulk, common_cell_line[cell_line_bulk], common_cell_line, adata_L1000)\n",
    "            for cell_line_bulk in common_cell_line.keys()\n",
    "        ]\n",
    "        \n",
    "        # 等待所有任务完成\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # 获取每个任务的结果，如果有异常，将在此处抛出\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1000运行CellOracle-并行版 - v2 使用delta直接加上去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prefix_method = 'CellOracle_v2'\n",
    "\n",
    "# CellOracle: use simulated_count\n",
    "# CellOracle_v2: use delte_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== cell line is A549\n",
      "==================== cell line is HepG2\n",
      "adata.shape is:  (500, 5155)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "==================== cell line is HT29\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "==================== cell line is MCF7\n",
      "adata.shape is:  (500, 5032)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (500, 5141)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "==================== cell line is SW480\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (409, 5450)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "==================== cell line is PC3\n",
      "adata.shape is:  (169, 5417)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "==================== cell line is A375\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (500, 3687)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n",
      "adata.shape is:  (500, 5379)\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "base_GRN.shape:  (37003, 1096)\n",
      "file exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e5869b9e314419b7d3a491e06ab274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629716fa2e67494ba898514634d9568d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c34c915ff44c04921a6fe329fffda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02997f890f33493586d6c3e38ab4b248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601b862d9e954761b7cf8a0fea7e02cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2f3d11f21d4ab5bb6954c6eec59ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c0b50a72284410a64fe1fc365b400d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3780\n",
      "common_perts num:  278\n",
      "common var to L1000 data is:  932\n",
      "L1000_total_perts num:  232\n",
      "common_perts num:  35\n",
      "common var to L1000 data is:  932\n",
      "5417 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1000_total_perts num:  3620\n",
      "common_perts num:  306\n",
      "common var to L1000 data is:  933\n",
      "L1000_total_perts num:  3669\n",
      "common_perts num:  291\n",
      "common var to L1000 data is:  945\n",
      "L1000_total_perts num:  3341\n",
      "common_perts num:  252\n",
      "common var to L1000 data is:  915\n",
      "L1000_total_perts num:  3649\n",
      "common_perts num:  280\n",
      "common var to L1000 data is:  930\n",
      "L1000_total_perts num:  3302\n",
      "common_perts num:  259\n",
      "common var to L1000 data is:  931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/278 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5155 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5379 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5032 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5450 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5141 genes were found in the adata. Note that Celloracle is intended to use around 1000-3000 genes, so the behavior with this number of genes may differ from what is expected.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'celltype' as categorical\n",
      "  0%|          | 0/259 [00:00<?, ?it/s]... storing 'x' as categorical\n",
      "  3%|▎         | 1/35 [00:31<17:42, 31.24s/it]it]... storing 'x' as categorical\n",
      "  1%|          | 2/278 [00:47<1:49:27, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHGEF12 is not in the tf_GRN_dict, no targets\n",
      "ARHGEF12 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/252 [00:55<3:51:32, 55.35s/it]... storing 'x' as categorical\n",
      "  1%|▏         | 4/278 [01:09<1:12:11, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARID5B is not in the tf_GRN_dict, no targets\n",
      "ARID5B is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/35 [01:00<16:36, 30.20s/it]it]... storing 'x' as categorical\n",
      "  0%|          | 1/291 [01:02<5:03:47, 62.85s/it]... storing 'x' as categorical\n",
      "  9%|▊         | 3/35 [01:41<18:48, 35.26s/it]it]... storing 'x' as categorical\n",
      "  1%|          | 2/306 [01:54<4:48:25, 56.92s/it]... storing 'x' as categorical\n",
      "  1%|          | 2/291 [02:03<4:55:43, 61.39s/it]... storing 'x' as categorical\n",
      " 11%|█▏        | 4/35 [02:11<16:57, 32.81s/it]it]... storing 'x' as categorical\n",
      "  1%|          | 3/306 [02:50<4:45:55, 56.62s/it]... storing 'x' as categorical\n",
      " 14%|█▍        | 5/35 [02:57<18:47, 37.59s/it]/it]... storing 'x' as categorical\n",
      "  2%|▏         | 4/259 [03:36<3:48:26, 53.75s/it]]... storing 'x' as categorical\n",
      "... storing 'x' as categorical\n",
      " 20%|██        | 7/35 [03:56<15:29, 33.20s/it]it]]... storing 'x' as categorical\n",
      "  2%|▏         | 5/280 [04:19<3:57:06, 51.73s/it]]... storing 'x' as categorical\n",
      "  2%|▏         | 5/259 [04:29<3:46:28, 53.50s/it]]... storing 'x' as categorical\n",
      "  2%|▏         | 5/306 [04:42<4:42:44, 56.36s/it]... storing 'x' as categorical\n",
      " 26%|██▌       | 9/35 [04:55<13:31, 31.20s/it]/it]... storing 'x' as categorical\n",
      " 29%|██▊       | 10/35 [05:25<12:47, 30.70s/it]t]]... storing 'x' as categorical\n",
      " 31%|███▏      | 11/35 [05:54<12:05, 30.22s/it]t]]... storing 'x' as categorical\n",
      "  2%|▎         | 7/280 [06:02<3:54:56, 51.63s/it]]... storing 'x' as categorical\n",
      "  3%|▎         | 7/259 [06:16<3:44:23, 53.42s/it]... storing 'x' as categorical\n",
      " 34%|███▍      | 12/35 [06:40<13:26, 35.08s/it]t]]... storing 'x' as categorical\n",
      "  3%|▎         | 8/280 [06:54<3:53:48, 51.58s/it]]... storing 'x' as categorical\n",
      "  3%|▎         | 8/259 [07:09<3:43:20, 53.39s/it]]... storing 'x' as categorical\n",
      "  2%|▏         | 6/291 [07:16<5:48:17, 73.32s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 22/278 [07:39<1:35:47, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBFB is not in the tf_GRN_dict, no targets\n",
      "CBFB is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 14/35 [07:39<11:16, 32.21s/it]t]... storing 'x' as categorical\n",
      " 43%|████▎     | 15/35 [08:08<10:26, 31.32s/it]t]]... storing 'x' as categorical\n",
      "  3%|▎         | 9/306 [08:25<4:36:03, 55.77s/it]]... storing 'x' as categorical\n",
      " 46%|████▌     | 16/35 [08:37<09:41, 30.63s/it]it]... storing 'x' as categorical\n",
      "  4%|▍         | 10/259 [08:56<3:41:31, 53.38s/it]... storing 'x' as categorical\n",
      "  4%|▎         | 10/280 [09:19<4:41:52, 62.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARX is not in the tf_GRN_dict, no targets\n",
      "ARX is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 49%|████▊     | 17/35 [09:23<10:33, 35.21s/it]it]... storing 'x' as categorical\n",
      " 51%|█████▏    | 18/35 [09:52<09:27, 33.36s/it]it]... storing 'x' as categorical\n",
      "  4%|▎         | 11/306 [10:17<4:34:19, 55.79s/it]... storing 'x' as categorical\n",
      "  3%|▎         | 8/291 [10:26<6:41:28, 85.12s/it]... storing 'x' as categorical\n",
      "  5%|▍         | 12/259 [10:42<3:39:24, 53.30s/it]... storing 'x' as categorical\n",
      " 57%|█████▋    | 20/35 [11:08<08:41, 34.78s/it]it]... storing 'x' as categorical\n",
      "  5%|▍         | 13/280 [11:23<3:44:48, 50.52s/it]... storing 'x' as categorical\n",
      "  5%|▌         | 13/259 [11:36<3:38:47, 53.36s/it]... storing 'x' as categorical\n",
      "  4%|▍         | 12/306 [11:45<5:21:40, 65.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARX is not in the tf_GRN_dict, no targets\n",
      "ARX is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13/252 [11:53<3:39:47, 55.18s/it]... storing 'x' as categorical\n",
      "  5%|▌         | 14/280 [12:15<3:45:11, 50.80s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 36/278 [12:38<1:32:32, 22.94s/it]... storing 'x' as categorical\n",
      "  5%|▌         | 14/259 [12:29<3:37:31, 53.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATF6 is not in the tf_GRN_dict, no targets\n",
      "ATF6 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14/252 [12:46<3:36:31, 54.58s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 37/278 [13:01<1:32:13, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLX2 is not in the tf_GRN_dict, no targets\n",
      "DLX2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/280 [13:06<3:44:45, 50.89s/it]... storing 'x' as categorical\n",
      "  6%|▌         | 16/259 [13:22<2:45:48, 40.94s/it]... storing 'x' as categorical\n",
      " 71%|███████▏  | 25/35 [13:34<05:02, 30.22s/it]it]... storing 'x' as categorical\n",
      "  6%|▌         | 15/252 [13:40<3:33:59, 54.18s/it]... storing 'x' as categorical\n",
      "  6%|▌         | 16/280 [14:18<4:10:57, 57.03s/it]... storing 'x' as categorical\n",
      " 15%|█▌        | 42/278 [14:33<1:22:10, 20.89s/it]... storing 'x' as categorical\n",
      "  6%|▋         | 16/252 [14:33<3:31:52, 53.86s/it]... storing 'x' as categorical\n",
      " 80%|████████  | 28/35 [15:02<03:26, 29.56s/it]it]... storing 'x' as categorical\n",
      "  7%|▋         | 17/252 [15:26<3:30:29, 53.74s/it]... storing 'x' as categorical\n",
      "  6%|▌         | 17/280 [15:32<4:30:12, 61.65s/it]... storing 'x' as categorical\n",
      "  7%|▋         | 19/259 [16:02<3:13:44, 48.44s/it]... storing 'x' as categorical\n",
      "  4%|▍         | 13/291 [16:06<5:49:24, 75.41s/it]... storing 'x' as categorical\n",
      " 89%|████████▊ | 31/35 [16:30<01:58, 29.51s/it]it]... storing 'x' as categorical\n",
      " 91%|█████████▏| 32/35 [16:59<01:28, 29.38s/it]it]... storing 'x' as categorical\n",
      " 18%|█▊        | 49/278 [17:12<1:26:20, 22.62s/it]... storing 'x' as categorical\n",
      "  6%|▌         | 19/306 [17:21<4:19:51, 54.33s/it]... storing 'x' as categorical\n",
      "  7%|▋         | 19/280 [17:36<4:33:25, 62.86s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 21/259 [17:49<3:21:41, 50.85s/it]... storing 'x' as categorical\n",
      "  5%|▌         | 15/291 [18:07<5:11:47, 67.78s/it]... storing 'x' as categorical\n",
      "  7%|▋         | 20/306 [18:17<4:20:35, 54.67s/it]... storing 'x' as categorical\n",
      "100%|██████████| 35/35 [18:44<00:00, 32.12s/it]it]\n",
      "  7%|▋         | 20/280 [18:49<4:45:29, 65.88s/it]... storing 'x' as categorical\n",
      "  7%|▋         | 21/306 [19:12<4:21:09, 54.98s/it]... storing 'x' as categorical\n",
      " 20%|█▉        | 55/278 [19:30<1:25:24, 22.98s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 21/280 [19:40<4:25:41, 61.55s/it]... storing 'x' as categorical\n",
      "  9%|▊         | 22/252 [19:52<3:23:41, 53.14s/it]... storing 'x' as categorical\n",
      "  7%|▋         | 22/306 [20:08<4:21:23, 55.22s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 22/280 [20:32<4:11:31, 58.50s/it]... storing 'x' as categorical\n",
      "  9%|▉         | 23/252 [20:45<3:22:56, 53.17s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 23/306 [21:04<4:21:08, 55.36s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 23/280 [21:23<4:00:56, 56.25s/it]... storing 'x' as categorical\n",
      " 10%|▉         | 25/259 [21:49<3:36:08, 55.42s/it]... storing 'x' as categorical\n",
      "  9%|▊         | 24/280 [22:14<3:53:34, 54.74s/it]... storing 'x' as categorical\n",
      "  6%|▌         | 18/291 [22:17<5:56:21, 78.32s/it]... storing 'x' as categorical\n",
      " 10%|▉         | 25/252 [22:31<3:20:24, 52.97s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 25/306 [22:54<4:18:52, 55.28s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 65/278 [23:18<1:21:27, 22.95s/it]... storing 'x' as categorical\n",
      "  9%|▉         | 25/280 [23:26<4:14:59, 60.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBFB is not in the tf_GRN_dict, no targets\n",
      "CBFB is filtered\n",
      "CDX2 is not in the tf_GRN_dict, no targets\n",
      "CDX2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      "  8%|▊         | 26/306 [23:49<4:18:01, 55.29s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 67/278 [24:03<1:19:55, 22.73s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 68/278 [24:26<1:20:02, 22.87s/it]... storing 'x' as categorical\n",
      " 11%|█         | 28/259 [24:29<3:28:28, 54.15s/it]... storing 'x' as categorical\n",
      "  9%|▉         | 27/306 [24:44<4:16:32, 55.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBFB is not in the tf_GRN_dict, no targets\n",
      "CBFB is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 11%|█         | 28/252 [25:09<3:17:09, 52.81s/it]... storing 'x' as categorical\n",
      "  7%|▋         | 21/291 [25:17<4:58:09, 66.26s/it]... storing 'x' as categorical\n",
      " 10%|█         | 29/280 [25:30<3:02:09, 43.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEBPD is not in the tf_GRN_dict, no targets\n",
      "CEBPD is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 29/306 [25:40<3:16:11, 42.49s/it]... storing 'x' as categorical\n",
      " 12%|█▏        | 29/252 [26:02<3:16:17, 52.81s/it]... storing 'x' as categorical\n",
      " 26%|██▋       | 73/278 [26:21<1:18:16, 22.91s/it]... storing 'x' as categorical\n",
      " 11%|█         | 31/280 [26:21<2:32:29, 36.75s/it]... storing 'x' as categorical\n",
      " 10%|▉         | 30/306 [26:35<3:30:00, 45.65s/it]... storing 'x' as categorical\n",
      " 12%|█▏        | 31/259 [27:10<3:23:52, 53.65s/it]... storing 'x' as categorical\n",
      "  8%|▊         | 23/291 [27:17<4:41:24, 63.00s/it]... storing 'x' as categorical\n",
      " 11%|█▏        | 32/280 [27:33<3:03:13, 44.33s/it]... storing 'x' as categorical\n",
      " 12%|█▏        | 31/252 [27:47<3:14:32, 52.82s/it]... storing 'x' as categorical\n",
      " 12%|█▏        | 32/259 [28:03<3:22:47, 53.60s/it]... storing 'x' as categorical\n",
      " 10%|█         | 32/306 [28:26<3:49:02, 50.15s/it]... storing 'x' as categorical\n",
      " 12%|█▏        | 33/280 [28:46<3:29:35, 50.91s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 33/259 [28:56<3:21:34, 53.52s/it]... storing 'x' as categorical\n",
      " 29%|██▉       | 81/278 [29:25<1:15:36, 23.03s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 33/252 [29:33<3:12:55, 52.86s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 34/259 [29:49<3:20:11, 53.39s/it]... storing 'x' as categorical\n",
      " 30%|██▉       | 83/278 [30:10<1:13:56, 22.75s/it]... storing 'x' as categorical\n",
      "  9%|▉         | 26/291 [30:17<4:30:21, 61.21s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 34/252 [30:26<3:11:43, 52.77s/it]... storing 'x' as categorical\n",
      " 12%|█▎        | 35/280 [30:50<3:51:31, 56.70s/it]... storing 'x' as categorical\n",
      " 11%|█▏        | 35/306 [31:13<4:02:48, 53.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREB3L1 is not in the tf_GRN_dict, no targets\n",
      "CREB3L1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      "  9%|▉         | 27/291 [31:18<4:28:16, 60.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEBPD is not in the tf_GRN_dict, no targets\n",
      "CEBPD is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35/252 [31:19<3:11:03, 52.83s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 36/280 [31:41<3:44:33, 55.22s/it]... storing 'x' as categorical\n",
      " 14%|█▍        | 36/252 [32:12<3:10:31, 52.92s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 89/278 [32:28<1:12:22, 22.98s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 37/280 [32:32<3:39:07, 54.10s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 90/278 [32:51<1:12:01, 22.99s/it]... storing 'x' as categorical\n",
      " 12%|█▏        | 38/306 [33:04<3:22:22, 45.31s/it]... storing 'x' as categorical\n",
      " 15%|█▍        | 38/259 [33:23<3:16:20, 53.30s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 92/278 [33:37<1:11:21, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOXA10 is not in the tf_GRN_dict, no targets\n",
      "HOXA10 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 38/280 [33:45<3:59:47, 59.45s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 39/306 [34:00<3:33:21, 47.95s/it]... storing 'x' as categorical\n",
      " 15%|█▌        | 38/252 [34:16<3:22:08, 56.68s/it]... storing 'x' as categorical\n",
      " 11%|█         | 31/291 [34:19<3:48:59, 52.84s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 40/306 [34:55<3:41:36, 49.99s/it]... storing 'x' as categorical\n",
      " 15%|█▌        | 39/252 [35:09<3:17:39, 55.68s/it]... storing 'x' as categorical\n",
      " 11%|█         | 32/291 [35:19<3:56:56, 54.89s/it]... storing 'x' as categorical\n",
      " 14%|█▍        | 40/280 [35:28<3:41:41, 55.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLX2 is not in the tf_GRN_dict, no targets\n",
      "DLX2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 40/259 [35:40<3:37:59, 59.72s/it]... storing 'x' as categorical\n",
      " 13%|█▎        | 41/306 [35:51<3:47:37, 51.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLX2 is not in the tf_GRN_dict, no targets\n",
      "DLX2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40/252 [36:02<3:13:41, 54.82s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 100/278 [36:18<1:05:58, 22.24s/it]... storing 'x' as categorical\n",
      " 11%|█▏        | 33/291 [36:20<4:02:37, 56.42s/it]... storing 'x' as categorical\n",
      " 14%|█▍        | 43/306 [36:47<2:59:57, 41.05s/it]]... storing 'x' as categorical\n",
      " 16%|█▋        | 41/252 [36:55<3:10:58, 54.30s/it]]... storing 'x' as categorical\n",
      " 37%|███▋      | 103/278 [37:27<1:06:26, 22.78s/it]... storing 'x' as categorical\n",
      " 16%|█▌        | 42/259 [37:26<3:24:08, 56.44s/it]... storing 'x' as categorical\n",
      " 15%|█▌        | 43/280 [37:53<3:29:48, 53.12s/it]]... storing 'x' as categorical\n",
      " 38%|███▊      | 105/278 [38:13<1:06:02, 22.90s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 43/259 [38:20<3:20:04, 55.58s/it]... storing 'x' as categorical\n",
      " 16%|█▌        | 44/280 [38:45<3:27:07, 52.66s/it]]... storing 'x' as categorical\n",
      " 38%|███▊      | 107/278 [39:00<1:05:30, 22.99s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 44/259 [39:13<3:16:44, 54.91s/it]]... storing 'x' as categorical\n",
      " 12%|█▏        | 36/291 [39:21<4:10:33, 58.95s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 44/252 [39:34<3:05:16, 53.45s/it]]... storing 'x' as categorical\n",
      " 17%|█▋        | 45/259 [40:07<3:14:25, 54.51s/it]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELK3 is not in the tf_GRN_dict, no targets\n",
      "ELK3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 40%|███▉      | 111/278 [40:32<1:04:15, 23.08s/it]... storing 'x' as categorical\n",
      " 15%|█▌        | 47/306 [40:30<3:41:52, 51.40s/it]... storing 'x' as categorical\n",
      " 18%|█▊        | 47/259 [41:00<2:27:08, 41.64s/it]]... storing 'x' as categorical\n",
      " 18%|█▊        | 46/252 [41:20<3:02:36, 53.19s/it]]... storing 'x' as categorical\n",
      " 16%|█▌        | 48/306 [41:26<3:46:38, 52.71s/it]... storing 'x' as categorical\n",
      " 41%|████      | 114/278 [41:40<1:02:14, 22.77s/it]... storing 'x' as categorical\n",
      " 41%|████▏     | 115/278 [42:03<1:02:07, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISL1 is not in the tf_GRN_dict, no targets\n",
      "ISL1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 47/252 [42:13<3:02:02, 53.28s/it]... storing 'x' as categorical\n",
      " 16%|█▌        | 49/306 [42:22<3:49:13, 53.52s/it] ... storing 'x' as categorical\n",
      " 13%|█▎        | 39/291 [42:22<4:11:31, 59.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLX2 is not in the tf_GRN_dict, no targets\n",
      "DLX2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 17%|█▋        | 48/280 [42:52<3:39:23, 56.74s/it]... storing 'x' as categorical\n",
      " 16%|█▋        | 50/306 [43:17<3:50:51, 54.11s/it]... storing 'x' as categorical\n",
      " 14%|█▍        | 41/291 [43:22<3:12:55, 46.30s/it]... storing 'x' as categorical\n",
      " 18%|█▊        | 49/280 [43:44<3:32:20, 55.15s/it]... storing 'x' as categorical\n",
      " 19%|█▉        | 49/252 [43:59<2:59:44, 53.12s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 51/306 [44:13<3:52:24, 54.68s/it]... storing 'x' as categorical\n",
      " 14%|█▍        | 42/291 [44:23<3:26:28, 49.75s/it]... storing 'x' as categorical\n",
      " 20%|█▉        | 50/252 [44:52<2:58:58, 53.16s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 52/306 [45:09<3:52:43, 54.97s/it]... storing 'x' as categorical\n",
      " 45%|████▍     | 125/278 [45:31<57:41, 22.62s/it]... storing 'x' as categorical\n",
      " 20%|██        | 52/259 [45:28<2:55:53, 50.98s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 53/306 [46:03<3:51:14, 54.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELF4 is not in the tf_GRN_dict, no targets\n",
      "ELF4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 46%|████▌     | 127/278 [46:16<56:37, 22.50s/it]... storing 'x' as categorical\n",
      " 20%|██        | 53/259 [46:21<2:57:28, 51.69s/it]... storing 'x' as categorical\n",
      " 19%|█▊        | 52/280 [46:37<3:29:42, 55.19s/it]... storing 'x' as categorical\n",
      " 21%|██        | 52/252 [47:06<3:24:50, 61.45s/it]... storing 'x' as categorical\n",
      " 21%|██        | 54/259 [47:15<2:58:27, 52.23s/it]... storing 'x' as categorical\n",
      " 19%|█▉        | 53/280 [47:27<3:23:13, 53.72s/it]... storing 'x' as categorical\n",
      " 47%|████▋     | 131/278 [47:47<55:33, 22.68s/it]... storing 'x' as categorical\n",
      " 21%|██        | 55/259 [48:08<2:58:30, 52.50s/it]... storing 'x' as categorical\n",
      " 48%|████▊     | 133/278 [48:32<54:37, 22.61s/it]... storing 'x' as categorical\n",
      " 19%|█▉        | 54/280 [48:38<3:41:57, 58.93s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 56/259 [49:01<2:58:29, 52.76s/it]... storing 'x' as categorical\n",
      " 19%|█▊        | 57/306 [49:19<3:41:53, 53.47s/it]... storing 'x' as categorical\n",
      " 16%|█▌        | 47/291 [49:20<3:53:36, 57.44s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 55/252 [49:42<3:01:36, 55.31s/it]... storing 'x' as categorical\n",
      " 19%|█▉        | 58/306 [50:14<3:42:57, 53.94s/it]... storing 'x' as categorical\n",
      " 50%|████▉     | 138/278 [50:27<53:35, 22.96s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 56/252 [50:35<2:57:49, 54.43s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 58/259 [50:48<2:58:04, 53.16s/it]... storing 'x' as categorical\n",
      " 20%|██        | 57/280 [51:09<3:17:59, 53.27s/it]... storing 'x' as categorical\n",
      " 17%|█▋        | 49/291 [51:19<3:55:42, 58.44s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 59/259 [51:41<2:57:17, 53.19s/it]... storing 'x' as categorical\n",
      " 20%|█▉        | 60/306 [52:03<3:42:35, 54.29s/it]... storing 'x' as categorical\n",
      " 51%|█████▏    | 143/278 [52:23<51:55, 23.07s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 58/252 [52:19<2:52:18, 53.29s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 60/259 [52:35<2:56:45, 53.30s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 59/252 [53:11<2:50:14, 52.92s/it]... storing 'x' as categorical\n",
      " 18%|█▊        | 51/291 [53:17<3:55:26, 58.86s/it]... storing 'x' as categorical\n",
      " 24%|██▎       | 61/259 [53:29<2:56:08, 53.38s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 60/252 [54:03<2:48:15, 52.58s/it]... storing 'x' as categorical\n",
      " 53%|█████▎    | 148/278 [54:18<49:53, 23.03s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 62/259 [54:22<2:55:16, 53.38s/it]... storing 'x' as categorical\n",
      " 21%|██        | 63/306 [54:47<3:40:31, 54.45s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 61/280 [55:11<3:32:47, 58.30s/it]... storing 'x' as categorical\n",
      " 54%|█████▍    | 151/278 [55:27<48:49, 23.07s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 63/259 [55:15<2:54:07, 53.30s/it]... storing 'x' as categorical\n",
      " 25%|██▍       | 62/252 [55:47<2:45:32, 52.28s/it]... storing 'x' as categorical\n",
      " 25%|██▍       | 64/259 [56:08<2:53:19, 53.33s/it]... storing 'x' as categorical\n",
      " 19%|█▊        | 54/291 [56:15<3:53:06, 59.02s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 63/252 [56:39<2:44:35, 52.25s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 65/259 [57:02<2:52:39, 53.40s/it]... storing 'x' as categorical\n",
      " 56%|█████▌    | 156/278 [57:22<46:31, 22.88s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 66/306 [57:30<3:37:54, 54.48s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 64/280 [57:42<3:10:49, 53.01s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 66/259 [57:55<2:51:46, 53.40s/it]... storing 'x' as categorical\n",
      " 19%|█▉        | 56/291 [58:13<3:51:20, 59.07s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 65/280 [58:32<3:07:02, 52.20s/it]... storing 'x' as categorical\n",
      " 26%|██▌       | 67/259 [58:49<2:50:35, 53.31s/it]... storing 'x' as categorical\n",
      " 58%|█████▊    | 161/278 [59:15<44:08, 22.64s/it]... storing 'x' as categorical\n",
      " 24%|██▎       | 66/280 [59:22<3:04:01, 51.60s/it]... storing 'x' as categorical\n",
      " 26%|██▋       | 68/259 [59:42<2:49:45, 53.33s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 67/252 [1:00:08<2:40:48, 52.16s/it]... storing 'x' as categorical\n",
      " 59%|█████▉    | 164/278 [1:00:23<43:01, 22.64s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 69/306 [1:00:14<3:35:32, 54.57s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 69/259 [1:00:35<2:48:46, 53.30s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 70/306 [1:01:09<3:34:45, 54.60s/it]... storing 'x' as categorical\n",
      " 20%|██        | 59/291 [1:01:10<3:48:46, 59.17s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 70/259 [1:01:29<2:48:01, 53.34s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 71/306 [1:02:04<3:34:07, 54.67s/it]... storing 'x' as categorical\n",
      " 61%|██████    | 169/278 [1:02:18<41:46, 22.99s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 71/259 [1:02:22<2:46:59, 53.29s/it]... storing 'x' as categorical\n",
      " 28%|██▊       | 70/252 [1:02:43<2:37:47, 52.02s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 70/280 [1:03:04<3:12:14, 54.93s/it]... storing 'x' as categorical\n",
      " 21%|██        | 61/291 [1:03:09<3:46:44, 59.15s/it]... storing 'x' as categorical\n",
      " 28%|██▊       | 71/252 [1:03:35<2:37:00, 52.05s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 71/280 [1:03:54<3:06:19, 53.49s/it]... storing 'x' as categorical\n",
      " 63%|██████▎   | 174/278 [1:04:13<39:49, 22.98s/it]... storing 'x' as categorical\n",
      " 21%|██▏       | 62/291 [1:04:08<3:45:45, 59.15s/it]... storing 'x' as categorical\n",
      " 26%|██▌       | 72/280 [1:04:45<3:02:04, 52.52s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 74/306 [1:04:48<3:31:27, 54.69s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 63/291 [1:05:07<3:44:57, 59.20s/it]... storing 'x' as categorical\n",
      " 29%|██▉       | 73/252 [1:05:20<2:35:12, 52.02s/it]... storing 'x' as categorical\n",
      " 25%|██▍       | 75/306 [1:05:43<3:30:33, 54.69s/it]... storing 'x' as categorical\n",
      " 64%|██████▍   | 179/278 [1:06:08<38:02, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRDM4 is not in the tf_GRN_dict, no targets\n",
      "PRDM4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 29%|██▉       | 74/252 [1:06:12<2:34:20, 52.03s/it]... storing 'x' as categorical\n",
      " 25%|██▍       | 76/306 [1:06:37<3:29:48, 54.73s/it]... storing 'x' as categorical\n",
      " 26%|██▋       | 74/280 [1:06:46<3:17:50, 57.62s/it]... storing 'x' as categorical\n",
      " 30%|██▉       | 75/252 [1:07:03<2:33:11, 51.93s/it]... storing 'x' as categorical\n",
      " 22%|██▏       | 65/291 [1:07:05<3:42:24, 59.04s/it]... storing 'x' as categorical\n",
      " 29%|██▉       | 76/259 [1:07:46<3:13:37, 63.48s/it]... storing 'x' as categorical\n",
      " 67%|██████▋   | 185/278 [1:08:01<32:43, 21.12s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 66/291 [1:08:04<3:41:05, 58.96s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 76/280 [1:08:26<3:03:00, 53.83s/it]... storing 'x' as categorical\n",
      " 30%|██▉       | 77/259 [1:08:39<3:03:35, 60.52s/it]... storing 'x' as categorical\n",
      " 68%|██████▊   | 188/278 [1:09:10<33:08, 22.10s/it]... storing 'x' as categorical\n",
      " 28%|██▊       | 77/280 [1:09:17<2:58:23, 52.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOXO4 is not in the tf_GRN_dict, no targets\n",
      "FOXO4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 30%|███       | 78/259 [1:09:33<2:56:23, 58.47s/it]... storing 'x' as categorical\n",
      " 68%|██████▊   | 190/278 [1:09:56<33:08, 22.60s/it]... storing 'x' as categorical\n",
      " 23%|██▎       | 68/291 [1:10:02<3:39:22, 59.02s/it]... storing 'x' as categorical\n",
      " 31%|███       | 79/259 [1:10:26<2:50:49, 56.94s/it]... storing 'x' as categorical\n",
      " 69%|██████▉   | 192/278 [1:10:42<32:45, 22.86s/it]... storing 'x' as categorical\n",
      " 29%|██▊       | 80/280 [1:10:57<2:21:39, 42.50s/it]... storing 'x' as categorical\n",
      " 26%|██▋       | 81/306 [1:11:10<3:24:51, 54.63s/it]... storing 'x' as categorical\n",
      " 31%|███       | 80/259 [1:11:20<2:46:49, 55.92s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 80/252 [1:11:53<2:35:07, 54.11s/it]... storing 'x' as categorical\n",
      " 24%|██▍       | 70/291 [1:12:00<3:37:54, 59.16s/it]... storing 'x' as categorical\n",
      " 31%|███▏      | 81/259 [1:12:13<2:43:51, 55.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIC2 is not in the tf_GRN_dict, no targets\n",
      "HIC2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 29%|██▉       | 82/280 [1:12:38<2:32:15, 46.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLI3 is not in the tf_GRN_dict, no targets\n",
      "GLI3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 81/252 [1:12:45<2:32:29, 53.51s/it]... storing 'x' as categorical\n",
      " 71%|███████   | 198/278 [1:12:59<30:32, 22.91s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 83/259 [1:13:07<2:03:31, 42.11s/it]... storing 'x' as categorical\n",
      " 30%|███       | 84/280 [1:13:28<2:00:38, 36.93s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 84/306 [1:13:55<3:22:37, 54.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLI3 is not in the tf_GRN_dict, no targets\n",
      "GLI3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 72%|███████▏  | 201/278 [1:14:08<29:24, 22.92s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 84/259 [1:14:00<2:10:46, 44.84s/it]... storing 'x' as categorical\n",
      " 30%|███       | 85/280 [1:14:39<2:26:33, 45.09s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 85/259 [1:14:53<2:16:30, 47.07s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 73/291 [1:14:58<3:35:10, 59.22s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 84/252 [1:15:21<2:27:01, 52.51s/it]... storing 'x' as categorical\n",
      " 28%|██▊       | 87/306 [1:15:44<2:45:18, 45.29s/it]... storing 'x' as categorical\n",
      " 74%|███████▍  | 206/278 [1:16:01<27:15, 22.71s/it]... storing 'x' as categorical\n",
      " 25%|██▌       | 74/291 [1:15:57<3:33:55, 59.15s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 86/259 [1:16:17<2:44:43, 57.13s/it]... storing 'x' as categorical\n",
      " 31%|███       | 87/280 [1:16:40<2:50:17, 52.94s/it]... storing 'x' as categorical\n",
      " 26%|██▌       | 75/291 [1:16:56<3:32:50, 59.12s/it]... storing 'x' as categorical\n",
      " 34%|███▎      | 87/259 [1:17:11<2:40:49, 56.10s/it]... storing 'x' as categorical\n",
      " 31%|███▏      | 88/280 [1:17:30<2:46:58, 52.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERPUD1 is not in the tf_GRN_dict, no targets\n",
      "HERPUD1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 89/306 [1:17:34<2:59:32, 49.64s/it]... storing 'x' as categorical\n",
      " 76%|███████▌  | 211/278 [1:17:56<25:39, 22.98s/it]... storing 'x' as categorical\n",
      " 34%|███▍      | 88/259 [1:18:04<2:37:27, 55.25s/it]... storing 'x' as categorical\n",
      " 29%|██▉       | 90/306 [1:18:29<3:04:07, 51.15s/it]... storing 'x' as categorical\n",
      " 77%|███████▋  | 213/278 [1:18:42<24:55, 23.00s/it]... storing 'x' as categorical\n",
      " 77%|███████▋  | 214/278 [1:19:05<24:32, 23.00s/it]... storing 'x' as categorical\n",
      " 32%|███▎      | 91/280 [1:19:11<2:14:22, 42.66s/it]... storing 'x' as categorical\n",
      " 30%|██▉       | 91/306 [1:19:24<3:07:09, 52.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERPUD1 is not in the tf_GRN_dict, no targets\n",
      "HERPUD1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 89/259 [1:19:28<3:00:00, 63.53s/it]... storing 'x' as categorical\n",
      " 78%|███████▊  | 216/278 [1:19:50<23:27, 22.71s/it]... storing 'x' as categorical\n",
      " 35%|███▌      | 89/252 [1:19:58<2:28:30, 54.66s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 92/280 [1:20:22<2:36:29, 49.94s/it]... storing 'x' as categorical\n",
      " 78%|███████▊  | 218/278 [1:20:37<22:53, 22.90s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 90/252 [1:20:50<2:25:19, 53.83s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 79/291 [1:20:53<3:29:17, 59.23s/it]... storing 'x' as categorical\n",
      " 35%|███▌      | 91/259 [1:21:15<2:43:49, 58.51s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 91/252 [1:21:42<2:23:01, 53.30s/it]... storing 'x' as categorical\n",
      " 27%|██▋       | 80/291 [1:21:53<3:28:23, 59.26s/it]... storing 'x' as categorical\n",
      " 34%|███▎      | 94/280 [1:22:03<2:35:19, 50.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMGA2 is not in the tf_GRN_dict, no targets\n",
      "HMGA2 is filtered\n",
      "HOMEZ is not in the tf_GRN_dict, no targets\n",
      "HOMEZ is filtered\n",
      "HOXA10 is not in the tf_GRN_dict, no targets\n",
      "HOXA10 is filtered\n",
      "HOXA5 is not in the tf_GRN_dict, no targets\n",
      "HOXA5 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 92/259 [1:22:08<2:38:38, 57.00s/it]... storing 'x' as categorical\n",
      " 37%|███▋      | 92/252 [1:22:34<2:21:05, 52.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOXA2 is not in the tf_GRN_dict, no targets\n",
      "HOXA2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 81%|████████  | 224/278 [1:22:55<20:48, 23.11s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 93/259 [1:23:02<2:34:43, 55.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOXA5 is not in the tf_GRN_dict, no targets\n",
      "HOXA5 is filtered\n",
      "HOXA6 is not in the tf_GRN_dict, no targets\n",
      "HOXA6 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 37%|███▋      | 94/252 [1:23:26<1:46:43, 40.53s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 100/280 [1:23:43<1:23:22, 27.79s/it]... storing 'x' as categorical\n",
      " 28%|██▊       | 82/291 [1:23:51<3:26:17, 59.22s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 97/306 [1:23:57<2:56:23, 50.64s/it]... storing 'x' as categorical\n",
      " 38%|███▊      | 95/252 [1:24:18<1:53:35, 43.41s/it]... storing 'x' as categorical\n",
      " 37%|███▋      | 97/259 [1:24:49<1:44:05, 38.55s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 101/280 [1:24:55<1:46:56, 35.85s/it]... storing 'x' as categorical\n",
      " 38%|███▊      | 96/252 [1:25:10<1:58:45, 45.68s/it]... storing 'x' as categorical\n",
      " 38%|███▊      | 98/259 [1:25:42<1:52:31, 41.93s/it]... storing 'x' as categorical\n",
      " 36%|███▋      | 102/280 [1:25:45<1:55:25, 38.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOXB7 is not in the tf_GRN_dict, no targets\n",
      "HOXB7 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 99/306 [1:25:47<3:01:33, 52.63s/it]... storing 'x' as categorical\n",
      " 38%|███▊      | 97/252 [1:26:03<2:02:39, 47.48s/it]... storing 'x' as categorical\n",
      " 84%|████████▍ | 233/278 [1:26:22<17:12, 22.94s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 100/306 [1:26:42<3:02:55, 53.28s/it]... storing 'x' as categorical\n",
      " 29%|██▉       | 85/291 [1:26:49<3:23:29, 59.27s/it]... storing 'x' as categorical\n",
      " 39%|███▉      | 98/252 [1:26:55<2:05:17, 48.82s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 101/306 [1:27:36<3:03:37, 53.75s/it]... storing 'x' as categorical\n",
      " 39%|███▉      | 99/252 [1:27:47<2:06:43, 49.70s/it]... storing 'x' as categorical\n",
      " 30%|██▉       | 86/291 [1:27:48<3:22:49, 59.37s/it]... storing 'x' as categorical\n",
      " 39%|███▉      | 101/259 [1:28:22<2:08:26, 48.78s/it]... storing 'x' as categorical\n",
      " 40%|███▉      | 100/252 [1:28:39<2:07:40, 50.40s/it]... storing 'x' as categorical\n",
      " 30%|██▉       | 87/291 [1:28:48<3:21:42, 59.33s/it]... storing 'x' as categorical\n",
      " 86%|████████▋ | 240/278 [1:29:02<14:27, 22.83s/it]... storing 'x' as categorical\n",
      " 40%|████      | 101/252 [1:29:31<2:08:04, 50.89s/it]... storing 'x' as categorical\n",
      " 87%|████████▋ | 242/278 [1:29:48<13:44, 22.91s/it]... storing 'x' as categorical\n",
      " 30%|███       | 88/291 [1:29:47<3:20:53, 59.38s/it]... storing 'x' as categorical\n",
      " 34%|███▍      | 104/306 [1:30:21<3:03:12, 54.42s/it]... storing 'x' as categorical\n",
      " 40%|███▉      | 103/259 [1:30:39<2:35:16, 59.72s/it]... storing 'x' as categorical\n",
      " 88%|████████▊ | 245/278 [1:30:56<12:34, 22.85s/it]... storing 'x' as categorical\n",
      " 31%|███       | 89/291 [1:30:47<3:19:58, 59.40s/it]... storing 'x' as categorical\n",
      " 41%|████      | 103/252 [1:31:16<2:08:09, 51.61s/it]... storing 'x' as categorical\n",
      " 40%|████      | 104/259 [1:31:33<2:29:38, 57.93s/it]... storing 'x' as categorical\n",
      " 31%|███       | 90/291 [1:31:46<3:18:58, 59.39s/it]... storing 'x' as categorical\n",
      " 35%|███▍      | 106/306 [1:32:10<3:01:49, 54.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOXA2 is not in the tf_GRN_dict, no targets\n",
      "HOXA2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 41%|████      | 105/259 [1:32:26<2:25:31, 56.70s/it]... storing 'x' as categorical\n",
      " 90%|████████▉ | 250/278 [1:32:51<10:41, 22.91s/it]... storing 'x' as categorical\n",
      " 42%|████▏     | 105/252 [1:33:00<2:06:59, 51.83s/it]... storing 'x' as categorical\n",
      " 41%|████      | 106/259 [1:33:20<2:22:05, 55.72s/it]... storing 'x' as categorical\n",
      " 40%|███▉      | 111/280 [1:33:30<2:47:11, 59.36s/it]... storing 'x' as categorical\n",
      " 32%|███▏      | 92/291 [1:33:45<3:16:48, 59.34s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 109/306 [1:34:00<2:28:39, 45.28s/it]... storing 'x' as categorical\n",
      " 40%|████      | 112/280 [1:34:20<2:38:45, 56.70s/it]... storing 'x' as categorical\n",
      " 92%|█████████▏| 255/278 [1:34:44<08:43, 22.77s/it]... storing 'x' as categorical\n",
      " 36%|███▌      | 110/306 [1:34:55<2:36:04, 47.78s/it]... storing 'x' as categorical\n",
      " 92%|█████████▏| 256/278 [1:35:07<08:23, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF136 is not in the tf_GRN_dict, no targets\n",
      "ZNF136 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 113/280 [1:35:11<2:32:52, 54.92s/it]... storing 'x' as categorical\n",
      " 43%|████▎     | 108/252 [1:35:37<2:05:30, 52.29s/it]... storing 'x' as categorical\n",
      " 93%|█████████▎| 259/278 [1:35:53<06:00, 18.97s/it]... storing 'x' as categorical\n",
      " 41%|████      | 114/280 [1:36:02<2:28:42, 53.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRF5 is not in the tf_GRN_dict, no targets\n",
      "IRF5 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 36%|███▋      | 111/306 [1:36:23<3:10:34, 58.64s/it]... storing 'x' as categorical\n",
      " 42%|████▏     | 109/259 [1:36:31<2:38:24, 63.36s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 95/291 [1:36:45<3:15:41, 59.91s/it]... storing 'x' as categorical\n",
      " 41%|████▏     | 116/280 [1:36:53<1:51:38, 40.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRF7 is not in the tf_GRN_dict, no targets\n",
      "IRF7 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 42%|████▏     | 110/259 [1:37:24<2:29:44, 60.30s/it]... storing 'x' as categorical\n",
      " 95%|█████████▍| 264/278 [1:37:49<05:11, 22.24s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 96/291 [1:37:45<3:15:00, 60.00s/it]]... storing 'x' as categorical\n",
      " 43%|████▎     | 111/259 [1:38:17<2:23:39, 58.24s/it]... storing 'x' as categorical\n",
      " 42%|████▎     | 119/280 [1:38:35<1:42:53, 38.35s/it]... storing 'x' as categorical\n",
      " 33%|███▎      | 97/291 [1:38:46<3:14:29, 60.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOXA2 is not in the tf_GRN_dict, no targets\n",
      "HOXA2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 44%|████▍     | 112/252 [1:39:08<2:02:57, 52.69s/it]... storing 'x' as categorical\n",
      " 43%|████▎     | 120/280 [1:39:26<1:50:24, 41.40s/it]... storing 'x' as categorical\n",
      " 97%|█████████▋| 269/278 [1:39:44<03:26, 22.96s/it]... storing 'x' as categorical\n",
      " 34%|███▍      | 99/291 [1:39:46<2:28:23, 46.37s/it]... storing 'x' as categorical\n",
      " 44%|████▎     | 113/259 [1:40:04<2:15:41, 55.76s/it]... storing 'x' as categorical\n",
      " 97%|█████████▋| 271/278 [1:40:30<02:39, 22.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF490 is not in the tf_GRN_dict, no targets\n",
      "ZNF490 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 121/280 [1:40:38<2:10:29, 49.24s/it]... storing 'x' as categorical\n",
      " 98%|█████████▊| 273/278 [1:40:53<01:28, 17.63s/it]... storing 'x' as categorical\n",
      " 38%|███▊      | 116/306 [1:41:01<2:57:54, 56.18s/it]... storing 'x' as categorical\n",
      " 99%|█████████▊| 274/278 [1:41:16<01:15, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF586 is not in the tf_GRN_dict, no targets\n",
      "ZNF586 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 44%|████▎     | 122/280 [1:41:29<2:10:53, 49.71s/it]... storing 'x' as categorical\n",
      " 46%|████▌     | 115/252 [1:41:47<2:00:32, 52.80s/it]... storing 'x' as categorical\n",
      " 38%|███▊      | 117/306 [1:41:56<2:56:04, 55.90s/it]... storing 'x' as categorical\n",
      "100%|██████████| 278/278 [1:42:23<00:00, 22.10s/it]\n",
      " 46%|████▌     | 116/252 [1:42:39<1:59:31, 52.73s/it]... storing 'x' as categorical\n",
      " 44%|████▍     | 124/280 [1:43:33<2:26:26, 56.33s/it]... storing 'x' as categorical\n",
      " 39%|███▉      | 120/306 [1:44:43<2:52:35, 55.67s/it]... storing 'x' as categorical\n",
      " 47%|████▋     | 119/252 [1:45:18<1:57:05, 52.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEF1 is not in the tf_GRN_dict, no targets\n",
      "LEF1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 121/306 [1:45:38<2:51:39, 55.67s/it]... storing 'x' as categorical\n",
      " 45%|████▌     | 127/280 [1:46:26<2:25:46, 57.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEF1 is not in the tf_GRN_dict, no targets\n",
      "LEF1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 122/306 [1:46:34<2:50:49, 55.70s/it]... storing 'x' as categorical\n",
      " 46%|████▌     | 129/280 [1:47:39<1:59:40, 47.55s/it]... storing 'x' as categorical\n",
      " 41%|████      | 124/306 [1:48:25<2:48:49, 55.66s/it]... storing 'x' as categorical\n",
      " 47%|████▋     | 123/259 [1:49:45<2:05:07, 55.20s/it]... storing 'x' as categorical\n",
      " 48%|████▊     | 124/259 [1:50:38<2:02:28, 54.43s/it]... storing 'x' as categorical\n",
      " 50%|█████     | 127/252 [1:51:26<1:45:49, 50.80s/it]... storing 'x' as categorical\n",
      " 48%|████▊     | 133/280 [1:52:26<2:38:36, 64.74s/it]... storing 'x' as categorical\n",
      " 49%|████▉     | 127/259 [1:53:45<2:06:34, 57.54s/it]... storing 'x' as categorical\n",
      " 52%|█████▏    | 130/252 [1:54:11<1:49:47, 54.00s/it]... storing 'x' as categorical\n",
      " 43%|████▎     | 131/306 [1:55:27<3:10:43, 65.39s/it]... storing 'x' as categorical\n",
      " 43%|████▎     | 132/306 [1:56:24<3:02:39, 62.98s/it]... storing 'x' as categorical\n",
      " 51%|█████     | 131/259 [1:57:45<2:00:58, 56.71s/it]... storing 'x' as categorical\n",
      " 54%|█████▎    | 135/252 [1:58:38<1:44:57, 53.82s/it]... storing 'x' as categorical\n",
      " 54%|█████▍    | 136/252 [1:59:31<1:43:35, 53.58s/it]... storing 'x' as categorical\n",
      " 54%|█████▍    | 137/252 [2:00:25<1:42:45, 53.61s/it]... storing 'x' as categorical\n",
      " 52%|█████▏    | 135/259 [2:01:41<2:06:32, 61.23s/it]... storing 'x' as categorical\n",
      " 53%|█████▎    | 136/259 [2:02:33<2:00:14, 58.66s/it]... storing 'x' as categorical\n",
      " 46%|████▌     | 140/306 [2:03:46<2:34:02, 55.68s/it]... storing 'x' as categorical\n",
      " 46%|████▌     | 141/306 [2:04:42<2:32:42, 55.53s/it]... storing 'x' as categorical\n",
      " 57%|█████▋    | 143/252 [2:05:46<1:37:36, 53.73s/it]... storing 'x' as categorical\n",
      " 57%|█████▋    | 144/252 [2:06:42<1:38:19, 54.62s/it]... storing 'x' as categorical\n",
      " 58%|█████▊    | 145/252 [2:07:37<1:37:42, 54.79s/it]... storing 'x' as categorical\n",
      " 58%|█████▊    | 146/252 [2:08:31<1:36:17, 54.51s/it]... storing 'x' as categorical\n",
      " 54%|█████▍    | 151/280 [2:08:50<1:57:20, 54.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFIL3 is not in the tf_GRN_dict, no targets\n",
      "NFIL3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 153/280 [2:09:47<1:30:06, 42.57s/it]... storing 'x' as categorical\n",
      " 55%|█████▌    | 154/280 [2:10:46<1:37:47, 46.57s/it]... storing 'x' as categorical\n",
      " 55%|█████▌    | 155/280 [2:12:04<1:54:16, 54.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NKX2-1 is not in the tf_GRN_dict, no targets\n",
      "NKX2-1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 60%|█████▉    | 150/252 [2:12:46<1:43:41, 60.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR2F2 is not in the tf_GRN_dict, no targets\n",
      "NR2F2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 157/280 [2:12:55<1:26:41, 42.29s/it]... storing 'x' as categorical\n",
      " 57%|█████▋    | 147/259 [2:14:03<1:50:19, 59.10s/it]... storing 'x' as categorical\n",
      " 57%|█████▋    | 148/259 [2:14:55<1:45:41, 57.13s/it]... storing 'x' as categorical\n",
      " 58%|█████▊    | 149/259 [2:15:48<1:42:20, 55.82s/it]... storing 'x' as categorical\n",
      " 50%|█████     | 154/306 [2:17:05<2:21:19, 55.78s/it]... storing 'x' as categorical\n",
      " 58%|█████▊    | 151/259 [2:18:03<1:53:30, 63.06s/it]... storing 'x' as categorical\n",
      " 59%|█████▊    | 152/259 [2:18:55<1:46:56, 59.97s/it]... storing 'x' as categorical\n",
      " 59%|█████▉    | 165/280 [2:20:05<1:39:20, 51.83s/it]... storing 'x' as categorical\n",
      " 59%|█████▉    | 166/280 [2:20:56<1:38:03, 51.61s/it]... storing 'x' as categorical\n",
      " 60%|█████▉    | 155/259 [2:22:04<1:51:20, 64.24s/it]... storing 'x' as categorical\n",
      " 60%|██████    | 168/280 [2:22:59<1:43:59, 55.71s/it]... storing 'x' as categorical\n",
      " 61%|██████    | 157/259 [2:23:49<1:39:20, 58.44s/it]... storing 'x' as categorical\n",
      " 65%|██████▌   | 165/252 [2:25:04<1:16:14, 52.58s/it]... storing 'x' as categorical\n",
      " 66%|██████▌   | 166/252 [2:25:57<1:15:14, 52.49s/it]... storing 'x' as categorical\n",
      " 61%|██████▏   | 172/280 [2:27:04<1:42:46, 57.09s/it]... storing 'x' as categorical\n",
      " 67%|██████▋   | 168/252 [2:27:41<1:13:26, 52.45s/it]... storing 'x' as categorical\n",
      " 62%|██████▏   | 173/280 [2:28:16<1:49:45, 61.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBX4 is not in the tf_GRN_dict, no targets\n",
      "PBX4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 167/306 [2:29:01<2:07:29, 55.04s/it]... storing 'x' as categorical\n",
      " 63%|██████▎   | 176/280 [2:29:58<1:20:28, 46.42s/it]... storing 'x' as categorical\n",
      " 55%|█████▌    | 169/306 [2:30:52<2:06:14, 55.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR1D2 is not in the tf_GRN_dict, no targets\n",
      "NR1D2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 164/259 [2:31:00<1:29:26, 56.49s/it]... storing 'x' as categorical\n",
      " 64%|██████▎   | 178/280 [2:32:01<1:29:22, 52.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPARD is not in the tf_GRN_dict, no targets\n",
      "PPARD is filtered\n",
      "PPARG is not in the tf_GRN_dict, no targets\n",
      "PPARG is filtered\n",
      "PRDM4 is not in the tf_GRN_dict, no targets\n",
      "PRDM4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 173/252 [2:32:04<1:09:10, 52.54s/it]... storing 'x' as categorical\n",
      " 69%|██████▉   | 174/252 [2:32:57<1:08:18, 52.55s/it]... storing 'x' as categorical\n",
      " 69%|██████▉   | 175/252 [2:33:50<1:07:33, 52.64s/it]... storing 'x' as categorical\n",
      " 66%|██████▌   | 184/280 [2:34:55<1:01:15, 38.29s/it]... storing 'x' as categorical\n",
      " 66%|██████▌   | 185/280 [2:35:46<1:05:04, 41.10s/it]... storing 'x' as categorical\n",
      " 71%|███████   | 178/252 [2:36:28<1:04:56, 52.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALL4 is not in the tf_GRN_dict, no targets\n",
      "SALL4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 186/280 [2:36:37<1:08:11, 43.52s/it]... storing 'x' as categorical\n",
      " 66%|██████▋   | 172/259 [2:38:01<1:16:35, 52.82s/it]... storing 'x' as categorical\n",
      " 67%|██████▋   | 173/259 [2:38:53<1:15:22, 52.58s/it]... storing 'x' as categorical\n",
      " 59%|█████▉    | 180/306 [2:40:05<1:54:44, 54.64s/it]... storing 'x' as categorical\n",
      " 59%|█████▉    | 181/306 [2:41:00<1:54:14, 54.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSR1 is not in the tf_GRN_dict, no targets\n",
      "OSR1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 175/259 [2:41:02<1:24:03, 60.04s/it]... storing 'x' as categorical\n",
      " 68%|██████▊   | 191/280 [2:41:57<1:32:07, 62.11s/it]... storing 'x' as categorical\n",
      " 69%|██████▊   | 192/280 [2:42:48<1:26:18, 58.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RXRB is not in the tf_GRN_dict, no targets\n",
      "RXRB is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 184/306 [2:42:51<1:32:35, 45.54s/it]... storing 'x' as categorical\n",
      " 60%|██████    | 185/306 [2:43:46<1:36:53, 48.05s/it]... storing 'x' as categorical\n",
      " 70%|██████▉   | 195/280 [2:44:51<1:11:39, 50.58s/it]... storing 'x' as categorical\n",
      " 61%|██████    | 187/306 [2:45:36<1:41:57, 51.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBX4 is not in the tf_GRN_dict, no targets\n",
      "PBX4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 196/280 [2:46:04<1:18:58, 56.41s/it]... storing 'x' as categorical\n",
      " 76%|███████▌  | 191/252 [2:47:01<53:19, 52.46s/it]t]... storing 'x' as categorical\n",
      " 71%|███████   | 183/259 [2:48:02<1:07:03, 52.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALL4 is not in the tf_GRN_dict, no targets\n",
      "SALL4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 71%|███████▏  | 185/259 [2:48:55<50:11, 40.69s/it]  ... storing 'x' as categorical\n",
      " 77%|███████▋  | 194/252 [2:49:41<51:07, 52.88s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP140 is not in the tf_GRN_dict, no targets\n",
      "SP140 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 186/259 [2:49:47<53:02, 43.60s/it]... storing 'x' as categorical\n",
      " 72%|███████▏  | 187/259 [2:50:39<55:05, 45.91s/it]t]... storing 'x' as categorical\n",
      " 64%|██████▎   | 195/306 [2:52:04<1:38:32, 53.27s/it]... storing 'x' as categorical\n",
      " 64%|██████▍   | 196/306 [2:53:00<1:38:48, 53.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRDM4 is not in the tf_GRN_dict, no targets\n",
      "PRDM4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 73%|███████▎  | 205/280 [2:54:05<1:12:01, 57.62s/it]... storing 'x' as categorical\n",
      " 74%|███████▎  | 206/280 [2:54:56<1:08:34, 55.59s/it]... storing 'x' as categorical\n",
      " 60%|█████▉    | 174/291 [2:55:08<1:57:04, 60.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBX4 is not in the tf_GRN_dict, no targets\n",
      "PBX4 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 207/280 [2:55:47<1:05:56, 54.21s/it]... storing 'x' as categorical\n",
      " 81%|████████  | 203/252 [2:57:01<43:10, 52.87s/it]t]... storing 'x' as categorical\n",
      " 75%|███████▍  | 209/280 [2:57:29<1:02:14, 52.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNAI2 is not in the tf_GRN_dict, no targets\n",
      "SNAI2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 204/252 [2:57:54<42:14, 52.80s/it]... storing 'x' as categorical\n",
      " 76%|███████▌  | 196/259 [2:59:06<55:52, 53.22s/it]t]... storing 'x' as categorical\n",
      " 76%|███████▌  | 212/280 [2:59:32<54:28, 48.07s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOX3 is not in the tf_GRN_dict, no targets\n",
      "SOX3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 197/259 [2:59:58<54:47, 53.02s/it]t]... storing 'x' as categorical\n",
      " 67%|██████▋   | 205/306 [3:00:55<1:32:12, 54.78s/it]... storing 'x' as categorical\n",
      " 77%|███████▋  | 216/280 [3:02:05<46:42, 43.79s/it]t]... storing 'x' as categorical\n",
      " 63%|██████▎   | 182/291 [3:02:06<1:44:48, 57.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRDM4 is not in the tf_GRN_dict, no targets\n",
      "PRDM4 is filtered\n",
      "PROX1 is not in the tf_GRN_dict, no targets\n",
      "PROX1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 217/280 [3:02:56<47:50, 45.57s/it]t]... storing 'x' as categorical\n",
      " 84%|████████▎ | 211/252 [3:04:01<35:44, 52.30s/it]t]... storing 'x' as categorical\n",
      " 84%|████████▍ | 212/252 [3:04:53<34:46, 52.17s/it]t]... storing 'x' as categorical\n",
      " 69%|██████▊   | 210/306 [3:06:01<1:31:12, 57.01s/it]... storing 'x' as categorical\n",
      " 79%|███████▉  | 221/280 [3:06:58<53:03, 53.95s/it]t]... storing 'x' as categorical\n",
      " 80%|███████▉  | 206/259 [3:07:49<46:21, 52.47s/it]t]... storing 'x' as categorical\n",
      " 70%|██████▉   | 213/306 [3:08:45<1:26:04, 55.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIM2 is not in the tf_GRN_dict, no targets\n",
      "SIM2 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 86%|████████▌ | 217/252 [3:09:13<30:21, 52.03s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFE3 is not in the tf_GRN_dict, no targets\n",
      "TFE3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 215/306 [3:09:39<1:04:23, 42.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIRT6 is not in the tf_GRN_dict, no targets\n",
      "SIRT6 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 224/280 [3:09:50<53:55, 57.78s/it]... storing 'x' as categorical\n",
      " 81%|████████  | 209/259 [3:10:26<43:32, 52.26s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT5A is not in the tf_GRN_dict, no targets\n",
      "STAT5A is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 220/252 [3:10:57<22:53, 42.92s/it]  ... storing 'x' as categorical\n",
      " 88%|████████▊ | 221/252 [3:11:48<23:20, 45.18s/it]t]... storing 'x' as categorical\n",
      " 82%|████████▏ | 212/259 [3:12:10<33:48, 43.15s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBX3 is not in the tf_GRN_dict, no targets\n",
      "TBX3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 227/280 [3:12:41<52:13, 59.12s/it]t]... storing 'x' as categorical\n",
      " 88%|████████▊ | 223/252 [3:13:32<23:23, 48.40s/it]t]... storing 'x' as categorical\n",
      " 83%|████████▎ | 215/259 [3:14:25<34:15, 46.72s/it]t]... storing 'x' as categorical\n",
      " 82%|████████▏ | 230/280 [3:15:32<49:27, 59.36s/it]t]... storing 'x' as categorical\n",
      " 84%|████████▍ | 217/259 [3:16:10<34:28, 49.25s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCF7L1 is not in the tf_GRN_dict, no targets\n",
      "TCF7L1 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 231/280 [3:16:22<46:10, 56.55s/it]... storing 'x' as categorical\n",
      " 74%|███████▎  | 225/306 [3:17:50<1:11:24, 52.89s/it]... storing 'x' as categorical\n",
      " 90%|█████████ | 228/252 [3:17:51<20:25, 51.08s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZBTB49 is not in the tf_GRN_dict, no targets\n",
      "ZBTB49 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 221/259 [3:18:48<28:29, 44.99s/it]t]... storing 'x' as categorical\n",
      " 84%|████████▍ | 235/280 [3:19:42<38:40, 51.56s/it]t]... storing 'x' as categorical\n",
      " 92%|█████████▏| 232/252 [3:20:43<16:00, 48.02s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF134 is not in the tf_GRN_dict, no targets\n",
      "ZNF134 is filtered\n",
      "ZNF136 is not in the tf_GRN_dict, no targets\n",
      "ZNF136 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 85%|████████▍ | 237/280 [3:21:43<39:33, 55.19s/it]t]... storing 'x' as categorical\n",
      " 94%|█████████▎| 236/252 [3:22:27<09:33, 35.86s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF232 is not in the tf_GRN_dict, no targets\n",
      "ZNF232 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 238/280 [3:22:34<37:37, 53.76s/it]... storing 'x' as categorical\n",
      " 94%|█████████▍| 238/252 [3:23:19<07:32, 32.30s/it]t]... storing 'x' as categorical\n",
      " 86%|████████▌ | 240/280 [3:24:35<37:38, 56.46s/it]t]... storing 'x' as categorical\n",
      " 86%|████████▌ | 241/280 [3:25:26<35:31, 54.65s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFE3 is not in the tf_GRN_dict, no targets\n",
      "TFE3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 89%|████████▉ | 230/259 [3:26:39<25:04, 51.86s/it]t]... storing 'x' as categorical\n",
      " 96%|█████████▋| 243/252 [3:27:39<07:03, 47.05s/it]t]... storing 'x' as categorical\n",
      " 88%|████████▊ | 245/280 [3:28:38<31:01, 53.20s/it]t]... storing 'x' as categorical\n",
      " 97%|█████████▋| 245/252 [3:29:22<05:44, 49.28s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF490 is not in the tf_GRN_dict, no targets\n",
      "ZNF490 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 238/306 [3:29:38<1:01:44, 54.48s/it]... storing 'x' as categorical\n",
      " 98%|█████████▊| 247/252 [3:30:13<03:13, 38.70s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF586 is not in the tf_GRN_dict, no targets\n",
      "ZNF586 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 234/259 [3:30:38<23:00, 55.23s/it]t]... storing 'x' as categorical\n",
      " 91%|█████████ | 235/259 [3:31:30<21:46, 54.44s/it]  ... storing 'x' as categorical\n",
      " 99%|█████████▉| 250/252 [3:31:57<01:15, 37.70s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF8 is not in the tf_GRN_dict, no targets\n",
      "ZNF8 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 236/259 [3:32:23<20:39, 53.90s/it]... storing 'x' as categorical\n",
      "100%|██████████| 252/252 [3:32:49<00:00, 50.67s/it]t]\n",
      " 92%|█████████▏| 237/259 [3:33:15<19:35, 53.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZBTB49 is not in the tf_GRN_dict, no targets\n",
      "ZBTB49 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 90%|████████▉ | 251/280 [3:34:20<28:20, 58.64s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZBTB48 is not in the tf_GRN_dict, no targets\n",
      "ZBTB48 is filtered\n",
      "ZBTB49 is not in the tf_GRN_dict, no targets\n",
      "ZBTB49 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 91%|█████████ | 254/280 [3:35:30<16:56, 39.08s/it]t]... storing 'x' as categorical\n",
      " 93%|█████████▎| 241/259 [3:35:52<13:47, 45.99s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF232 is not in the tf_GRN_dict, no targets\n",
      "ZNF232 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 255/280 [3:36:20<17:13, 41.36s/it]... storing 'x' as categorical\n",
      " 91%|█████████▏| 256/280 [3:37:10<17:19, 43.33s/it]t]... storing 'x' as categorical\n",
      " 92%|█████████▏| 257/280 [3:38:21<19:12, 50.10s/it]t]... storing 'x' as categorical\n",
      " 95%|█████████▍| 246/259 [3:39:22<09:59, 46.09s/it]t]... storing 'x' as categorical\n",
      " 92%|█████████▎| 259/280 [3:40:22<18:53, 53.99s/it]t]... storing 'x' as categorical\n",
      " 82%|████████▏ | 251/306 [3:41:25<49:48, 54.33s/it]t]... storing 'x' as categorical\n",
      " 82%|████████▏ | 252/306 [3:42:19<48:56, 54.38s/it]t]... storing 'x' as categorical\n",
      " 83%|████████▎ | 253/306 [3:43:13<47:55, 54.25s/it]t]... storing 'x' as categorical\n",
      " 97%|█████████▋| 251/259 [3:43:43<06:49, 51.19s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF490 is not in the tf_GRN_dict, no targets\n",
      "ZNF490 is filtered\n",
      "ZNF502 is not in the tf_GRN_dict, no targets\n",
      "ZNF502 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 254/306 [3:44:08<46:59, 54.23s/it]... storing 'x' as categorical\n",
      " 94%|█████████▍| 263/280 [3:44:44<17:37, 62.19s/it]t]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF317 is not in the tf_GRN_dict, no targets\n",
      "ZNF317 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 254/259 [3:45:06<03:09, 37.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF554 is not in the tf_GRN_dict, no targets\n",
      "ZNF554 is filtered\n",
      "ZNF563 is not in the tf_GRN_dict, no targets\n",
      "ZNF563 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 99%|█████████▉| 257/259 [3:45:59<00:57, 28.97s/it]t]... storing 'x' as categorical\n",
      "100%|█████████▉| 258/259 [3:46:51<00:33, 33.10s/it]t]... storing 'x' as categorical\n",
      "100%|██████████| 259/259 [3:47:44<00:00, 52.76s/it]  \n",
      " 95%|█████████▌| 267/280 [3:47:55<11:58, 55.29s/it]... storing 'x' as categorical\n",
      " 96%|█████████▌| 268/280 [3:49:06<11:53, 59.45s/it]... storing 'x' as categorical\n",
      " 80%|███████▉  | 232/291 [3:49:17<57:47, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBX3 is not in the tf_GRN_dict, no targets\n",
      "TBX3 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 269/280 [3:49:56<10:25, 56.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF436 is not in the tf_GRN_dict, no targets\n",
      "ZNF436 is filtered\n",
      "ZNF449 is not in the tf_GRN_dict, no targets\n",
      "ZNF449 is filtered\n",
      "ZNF490 is not in the tf_GRN_dict, no targets\n",
      "ZNF490 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 98%|█████████▊| 273/280 [3:50:46<03:27, 29.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF554 is not in the tf_GRN_dict, no targets\n",
      "ZNF554 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 98%|█████████▊| 275/280 [3:51:57<02:36, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF586 is not in the tf_GRN_dict, no targets\n",
      "ZNF586 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 86%|████████▋ | 264/306 [3:53:09<37:52, 54.11s/it]... storing 'x' as categorical\n",
      " 87%|████████▋ | 265/306 [3:54:04<37:01, 54.18s/it]... storing 'x' as categorical\n",
      " 87%|████████▋ | 266/306 [3:54:58<36:07, 54.18s/it]... storing 'x' as categorical\n",
      "100%|██████████| 280/280 [3:55:38<00:00, 50.49s/it]\n",
      " 87%|████████▋ | 267/306 [3:55:52<35:14, 54.23s/it]... storing 'x' as categorical\n",
      " 88%|████████▊ | 268/306 [3:56:46<34:15, 54.09s/it]... storing 'x' as categorical\n",
      " 88%|████████▊ | 269/306 [3:57:40<33:18, 54.02s/it]... storing 'x' as categorical\n",
      " 88%|████████▊ | 270/306 [3:58:34<32:21, 53.94s/it]... storing 'x' as categorical\n",
      " 89%|████████▊ | 271/306 [3:59:28<31:27, 53.93s/it]... storing 'x' as categorical\n",
      " 89%|████████▉ | 272/306 [4:00:22<30:34, 53.96s/it]... storing 'x' as categorical\n",
      " 89%|████████▉ | 273/306 [4:01:15<29:38, 53.91s/it]... storing 'x' as categorical\n",
      " 90%|████████▉ | 274/306 [4:02:09<28:46, 53.95s/it]... storing 'x' as categorical\n",
      " 90%|████████▉ | 275/306 [4:03:03<27:53, 53.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZBTB49 is not in the tf_GRN_dict, no targets\n",
      "ZBTB49 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 277/306 [4:03:57<20:03, 41.49s/it]... storing 'x' as categorical\n",
      " 85%|████████▌ | 248/291 [4:03:58<41:55, 58.50s/it]... storing 'x' as categorical\n",
      " 91%|█████████ | 278/306 [4:05:22<24:24, 52.32s/it]... storing 'x' as categorical\n",
      " 91%|█████████ | 279/306 [4:06:16<23:42, 52.68s/it]... storing 'x' as categorical\n",
      " 92%|█████████▏| 280/306 [4:07:10<22:57, 52.97s/it]... storing 'x' as categorical\n",
      " 92%|█████████▏| 281/306 [4:08:03<22:08, 53.13s/it]... storing 'x' as categorical\n",
      " 92%|█████████▏| 282/306 [4:08:57<21:19, 53.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF136 is not in the tf_GRN_dict, no targets\n",
      "ZNF136 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 93%|█████████▎| 285/306 [4:10:45<15:33, 44.47s/it]... storing 'x' as categorical\n",
      " 93%|█████████▎| 286/306 [4:11:39<15:38, 46.95s/it]... storing 'x' as categorical\n",
      " 94%|█████████▍| 287/306 [4:12:33<15:28, 48.85s/it]... storing 'x' as categorical\n",
      " 94%|█████████▍| 288/306 [4:13:27<15:04, 50.24s/it]... storing 'x' as categorical\n",
      " 94%|█████████▍| 289/306 [4:14:21<14:31, 51.26s/it]... storing 'x' as categorical\n",
      " 95%|█████████▍| 290/306 [4:15:15<13:52, 52.02s/it]... storing 'x' as categorical\n",
      " 89%|████████▉ | 260/291 [4:15:39<30:09, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZBTB48 is not in the tf_GRN_dict, no targets\n",
      "ZBTB48 is filtered\n",
      "ZBTB49 is not in the tf_GRN_dict, no targets\n",
      "ZBTB49 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 291/306 [4:16:09<13:08, 52.58s/it]... storing 'x' as categorical\n",
      " 95%|█████████▌| 292/306 [4:17:02<12:20, 52.87s/it]... storing 'x' as categorical\n",
      " 96%|█████████▌| 293/306 [4:17:56<11:31, 53.16s/it]... storing 'x' as categorical\n",
      " 96%|█████████▌| 294/306 [4:18:50<10:40, 53.37s/it]... storing 'x' as categorical\n",
      " 91%|█████████▏| 266/291 [4:19:32<20:09, 48.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF140 is not in the tf_GRN_dict, no targets\n",
      "ZNF140 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 295/306 [4:19:43<09:47, 53.38s/it]... storing 'x' as categorical\n",
      " 97%|█████████▋| 296/306 [4:20:37<08:54, 53.49s/it]... storing 'x' as categorical\n",
      " 97%|█████████▋| 298/306 [4:22:24<07:08, 53.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF490 is not in the tf_GRN_dict, no targets\n",
      "ZNF490 is filtered\n",
      "ZNF502 is not in the tf_GRN_dict, no targets\n",
      "ZNF502 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 98%|█████████▊| 301/306 [4:23:18<02:47, 33.57s/it]... storing 'x' as categorical\n",
      " 99%|█████████▊| 302/306 [4:24:12<02:31, 37.87s/it]... storing 'x' as categorical\n",
      " 99%|█████████▉| 303/306 [4:25:06<02:04, 41.59s/it]... storing 'x' as categorical\n",
      " 99%|█████████▉| 304/306 [4:26:00<01:29, 44.60s/it]... storing 'x' as categorical\n",
      "100%|█████████▉| 305/306 [4:26:54<00:47, 47.07s/it]... storing 'x' as categorical\n",
      "100%|██████████| 306/306 [4:27:48<00:00, 52.51s/it]\n",
      "... storing 'x' as categorical\n",
      " 95%|█████████▍| 276/291 [4:28:16<14:11, 56.75s/it]... storing 'x' as categorical\n",
      " 95%|█████████▌| 277/291 [4:29:14<13:18, 57.05s/it]... storing 'x' as categorical\n",
      " 96%|█████████▌| 278/291 [4:30:11<12:23, 57.22s/it]... storing 'x' as categorical\n",
      " 96%|█████████▌| 279/291 [4:31:09<11:28, 57.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF436 is not in the tf_GRN_dict, no targets\n",
      "ZNF436 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 97%|█████████▋| 281/291 [4:32:07<07:22, 44.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF490 is not in the tf_GRN_dict, no targets\n",
      "ZNF490 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 97%|█████████▋| 283/291 [4:33:05<05:05, 38.19s/it]... storing 'x' as categorical\n",
      " 98%|█████████▊| 284/291 [4:34:02<04:57, 42.45s/it]... storing 'x' as categorical\n",
      " 98%|█████████▊| 285/291 [4:35:00<04:36, 46.11s/it]... storing 'x' as categorical\n",
      " 98%|█████████▊| 286/291 [4:35:58<04:05, 49.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZNF582 is not in the tf_GRN_dict, no targets\n",
      "ZNF582 is filtered\n",
      "ZNF586 is not in the tf_GRN_dict, no targets\n",
      "ZNF586 is filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'x' as categorical\n",
      " 99%|█████████▉| 289/291 [4:36:56<01:07, 33.52s/it]... storing 'x' as categorical\n",
      "100%|█████████▉| 290/291 [4:37:53<00:38, 38.37s/it]... storing 'x' as categorical\n",
      "100%|██████████| 291/291 [4:38:51<00:00, 57.50s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from scipy.spatial.distance import cdist\n",
    "import concurrent.futures\n",
    "import json\n",
    "\n",
    "# 定义处理每个 cell_line_single 的函数\n",
    "def process_cell_line(cell_line_bulk, cell_line_single, common_cell_line, adata_L1000):\n",
    "    print('=' * 20, f'cell line is {cell_line_single}')\n",
    "\n",
    "    #===================prepare data\n",
    "    if cell_line_bulk in ['PC3', 'A375']:\n",
    "        save_dir_adata = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/single_cell_data/SCP542'\n",
    "    else:\n",
    "        save_dir_adata = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/single_cell_data/CNP0003658'\n",
    "    adata_rna = sc.read(os.path.join(save_dir_adata, cell_line_bulk, f'adata_{cell_line_bulk}.h5ad'))\n",
    "\n",
    "    # - consctrut corr mtx\n",
    "    if not isinstance(adata_rna.X, np.ndarray):\n",
    "        adata_rna.X = adata_rna.X.toarray()\n",
    "    # corr_mtx = np.corrcoef(adata_rna.X.T)\n",
    "    \n",
    "    # - get var_names\n",
    "    var_names = list(adata_rna.var_names)\n",
    "    \n",
    "    # - get common pert\n",
    "    adata_L1000_sub = adata_L1000[adata_L1000.obs['cell_id']==cell_line_bulk]\n",
    "    L1000_total_perts = np.unique(adata_L1000_sub.obs['pert_iname'])\n",
    "    \n",
    "    \n",
    "    n_cells_downsample = 10000\n",
    "    threshold_number = 10000\n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    # - get control adata\n",
    "    adata = adata_rna.copy()\n",
    "    adata.obs['celltype'] = cell_line_bulk\n",
    "    print(f'adata.shape is: ',adata.shape)\n",
    "\n",
    "    # -- get the baseGRN\n",
    "    # Load TF info which was made from mouse cell atlas dataset.\n",
    "    base_GRN = co.data.load_human_promoter_base_GRN()\n",
    "    print('base_GRN.shape: ', base_GRN.shape)\n",
    "\n",
    "    tmp_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/L1000'\n",
    "    save_prefix = f'CellOracle/{cell_line_bulk}' # use result of K562 to do the direct transfer\n",
    "    os.makedirs(os.path.join(tmp_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "    save_dir = os.path.join(tmp_dir, save_prefix)\n",
    "    if os.path.exists(os.path.join(save_dir, \"ctrl.celloracle.oracle\")):\n",
    "        print('file exists')\n",
    "        oracle = co.load_hdf5(os.path.join(save_dir, \"ctrl.celloracle.oracle\"))\n",
    "        links = co.load_hdf5(file_path=os.path.join(save_dir, \"ctrl.celloracle.links\"))\n",
    "        \n",
    "    else:\n",
    "\n",
    "        # - start CellOracle process for the whole ctrl\n",
    "\n",
    "        # -- keep raw cont data before log transformation\n",
    "        adata.raw = adata\n",
    "        if not isinstance(adata.raw.X, np.ndarray):\n",
    "            adata.layers[\"raw_count\"] = (np.exp(adata.raw.X.toarray())-1).copy()\n",
    "        else:\n",
    "            adata.layers[\"raw_count\"] = (np.exp(adata.raw.X)-1).copy()\n",
    "            \n",
    "        # -- get umap \n",
    "        sc.pp.scale(adata)\n",
    "        # PCA\n",
    "        sc.tl.pca(adata, svd_solver='arpack', random_state=2022)\n",
    "        # UMAP\n",
    "        sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20, random_state=2022)\n",
    "        sc.tl.umap(adata,random_state=2022)\n",
    "\n",
    "        # -- Random downsampling into 30K cells if the anndata object include more than 30 K cells.\n",
    "        if adata.shape[0] > n_cells_downsample:\n",
    "            # Let's dowmsample into 30K cells\n",
    "            sc.pp.subsample(adata, n_obs=n_cells_downsample, random_state=123)\n",
    "        print(f\"Cell number is :{adata.shape[0]}\")\n",
    "\n",
    "        # -- Instantiate Oracle object\n",
    "        oracle = co.Oracle()\n",
    "\n",
    "        # -- Check data in anndata\n",
    "        print(\"Metadata columns :\", list(adata.obs.columns))\n",
    "        print(\"Dimensional reduction: \", list(adata.obsm.keys()))\n",
    "\n",
    "        # -- In this notebook, we use the unscaled mRNA count for the nput of Oracle object.\n",
    "        adata.X = adata.layers[\"raw_count\"].copy()\n",
    "\n",
    "        # -- Instantiate Oracle object.\n",
    "        oracle.import_anndata_as_raw_count(adata=adata,\n",
    "                                        cluster_column_name=\"celltype\",\n",
    "                                        embedding_name=\"X_umap\")\n",
    "\n",
    "        # -- You can load TF info dataframe with the following code.\n",
    "        oracle.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "        # -- knn imputation, this step is needed for the whole ctrl\n",
    "        # Perform PCA\n",
    "        oracle.perform_PCA()\n",
    "\n",
    "        # Select important PCs\n",
    "        plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])\n",
    "        n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]\n",
    "        plt.axvline(n_comps, c=\"k\")\n",
    "        plt.show()\n",
    "        print(n_comps)\n",
    "        n_comps = min(n_comps, 50)\n",
    "\n",
    "        n_cell = oracle.adata.shape[0]\n",
    "        print(f\"cell number is :{n_cell}\")\n",
    "\n",
    "        k = int(0.025*n_cell)\n",
    "        print(f\"Auto-selected k is :{k}\")\n",
    "\n",
    "        oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,\n",
    "                            b_maxl=k*4, n_jobs=4)\n",
    "\n",
    "        # model_prefix = ''\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        # -- save the oracle\n",
    "        oracle.to_hdf5(os.path.join(save_dir, \"ctrl.celloracle.oracle\"))\n",
    "\n",
    "        # -- get the links\n",
    "        # Calculate GRN for each population in \"louvain_annot\" clustering unit.\n",
    "        # This step may take some time.(~30 minutes)\n",
    "        links = oracle.get_links(cluster_name_for_GRN_unit=\"celltype\", alpha=10,\n",
    "                                verbose_level=10)\n",
    "\n",
    "        # -- Save Links object.\n",
    "        links.to_hdf5(file_path=os.path.join(save_dir, \"ctrl.celloracle.links\"))\n",
    "\n",
    "\n",
    "    # -- filter and get the coef_mtx\n",
    "    links.filter_links(threshold_number=threshold_number,\n",
    "                        p=0.001,\n",
    "                        weight='coef_abs')\n",
    "    oracle.get_cluster_specific_TFdict_from_Links(links_object=links)\n",
    "    oracle.fit_GRN_for_simulation(alpha=10,\n",
    "                                use_cluster_specific_TFdict=True)\n",
    "    \n",
    "    ###################################################\n",
    "    # - get all the TFs in the base_GRN\n",
    "    TFdict = import_TF_data(TF_info_matrix=base_GRN)\n",
    "    tf_target_dict = {}\n",
    "    for target, gene_set in TFdict.items():\n",
    "        for tf in gene_set:\n",
    "            if tf not in tf_target_dict:\n",
    "                tf_target_dict[tf] = []\n",
    "                tf_target_dict[tf].append(target)\n",
    "            else:\n",
    "                tf_target_dict[tf].append(target)\n",
    "    total_tf_list = list(tf_target_dict.keys())\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #####################################################\n",
    "    var_names = list(adata.var_names)    \n",
    "    single_total_perts = np.intersect1d(total_tf_list, adata.var_names)\n",
    "    common_perts = np.intersect1d(single_total_perts, L1000_total_perts)\n",
    "    print('L1000_total_perts num: ', len(L1000_total_perts))\n",
    "    print('common_perts num: ', len(common_perts))\n",
    "    print('common var to L1000 data is: ', len(np.intersect1d(var_names, adata_L1000.var_names)))\n",
    "\n",
    "    ###########################################\n",
    "    celltype = adata.obs['celltype'].unique()[0]\n",
    "\n",
    "    # - get the tf_GRN_dict, to check whether pert have regulatory relations\n",
    "    gene_GRN_mtx = oracle.coef_matrix_per_cluster[celltype].copy()\n",
    "    tf_GRN_mtx = gene_GRN_mtx[~(gene_GRN_mtx == 0).all(axis=1)]\n",
    "    # - get TF-target pair and the regulatory values\n",
    "    tf_GRN_dict = {} # the tf to targets\n",
    "    for i in range(len(tf_GRN_mtx)):\n",
    "        tmp = tf_GRN_mtx.iloc[i,:]\n",
    "        tmp = tmp[tmp!=0]\n",
    "\n",
    "        tf_GRN_dict[tf_GRN_mtx.index[i]] = {}\n",
    "        for j in range(len(tmp)):\n",
    "            tf_GRN_dict[tf_GRN_mtx.index[i]][tmp.index[j]] = tmp.values[j]\n",
    "\n",
    "    ###########################################        \n",
    "    # - get oracle_ctrl\n",
    "    adata_rna.obs['celltype'] = cell_line_bulk\n",
    "    adata_ctrl = adata_rna.copy()\n",
    "    # keep raw cont data before log transformation\n",
    "    adata_ctrl.raw = adata_ctrl\n",
    "\n",
    "    # the result will be recovered in normalized_count\n",
    "    if not isinstance(adata_ctrl.raw.X, np.ndarray):\n",
    "        adata_ctrl.layers[\"raw_count\"] = (np.exp(adata_ctrl.raw.X.toarray())-1).copy()\n",
    "    else:\n",
    "        adata_ctrl.layers[\"raw_count\"] = (np.exp(adata_ctrl.raw.X)-1).copy()\n",
    "        \n",
    "    sc.pp.scale(adata_ctrl)\n",
    "    # PCA\n",
    "    sc.tl.pca(adata_ctrl, svd_solver='arpack', random_state=2022)\n",
    "\n",
    "    # Diffusion map\n",
    "    sc.pp.neighbors(adata_ctrl, n_neighbors=4, n_pcs=20, random_state=2022)\n",
    "    sc.tl.umap(adata_ctrl,random_state=2022)\n",
    "\n",
    "    # Instantiate Oracle object\n",
    "    oracle_ctrl = co.Oracle()\n",
    "\n",
    "    # In this notebook, we use the unscaled mRNA count for the nput of Oracle object.\n",
    "    adata_ctrl.X = adata_ctrl.layers[\"raw_count\"].copy()\n",
    "\n",
    "    # Instantiate Oracle object.\n",
    "    oracle_ctrl.import_anndata_as_raw_count(adata=adata_ctrl,\n",
    "                                    cluster_column_name=\"celltype\",\n",
    "                                    embedding_name=\"X_umap\")\n",
    "\n",
    "    # You can load TF info dataframe with the following code.\n",
    "    oracle_ctrl.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "    # get the imputed_count, here we dont do the impute to get the prediction\n",
    "    oracle_ctrl.adata.layers[\"imputed_count\"] = oracle_ctrl.adata.layers[\"normalized_count\"].copy()\n",
    "\n",
    "    # get the coef from the whole ctrl\n",
    "    oracle_ctrl.coef_matrix_per_cluster = oracle.coef_matrix_per_cluster\n",
    "    \n",
    "    pert_gene_rank_dict = {} \n",
    "    for pert in tqdm(common_perts):\n",
    "        \n",
    "\n",
    "        # - this is for crispra\n",
    "        gois = [pert]\n",
    "        goi_dict = {}\n",
    "\n",
    "        # - all data in L1000 is knockdown\n",
    "        for goi in gois:\n",
    "            # -- if original value is zero\n",
    "            if np.mean(adata_rna[:,goi].X.toarray())==0:\n",
    "                print(f'{goi} ctrl expression is 0')\n",
    "                continue\n",
    "            # -- if the TF has no targets\n",
    "            if goi not in list(tf_GRN_dict.keys()):\n",
    "                print(f'{goi} is not in the tf_GRN_dict, no targets')\n",
    "                continue\n",
    "            goi_dict[goi] = 0\n",
    "        if len(goi_dict) == 0:\n",
    "            print(f'{pert} is filtered')\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Enter perturbation conditions to simulate signal propagation after the perturbation.\n",
    "        oracle_ctrl.simulate_shift(perturb_condition=goi_dict,\n",
    "                            n_propagation=3)\n",
    "        # - get the prediction; delta_X = simulated_count - imputed_count\n",
    "        delta_X, simulated_count = oracle_ctrl.adata.layers[\"delta_X\"], oracle_ctrl.adata.layers[\"simulated_count\"]\n",
    "\n",
    "\n",
    "        # - create adata_pert\n",
    "        adata_pert = adata_rna.copy()\n",
    "        if save_prefix_method == 'CellOracle':\n",
    "            adata_pert.X = simulated_count\n",
    "        if save_prefix_method == 'CellOracle_v2':\n",
    "            adata_pert.X += delta_X\n",
    "        adata_pert.X[adata_pert.X < 0] = 0\n",
    "        adata_pert.obs_names = [i+f'_{pert}' for i in adata_pert.obs_names]\n",
    "\n",
    "        # - adata_ctrl\n",
    "        adata_ctrl = adata_rna.copy()\n",
    "\n",
    "        adata_ctrl.obs['batch'] = 'ctrl'\n",
    "        adata_pert.obs['batch'] = 'pert'\n",
    "\n",
    "        adata_concat = ad.concat([adata_ctrl, adata_pert])\n",
    "        adata_concat.obs['batch'] = adata_concat.obs['batch'].astype('category') \n",
    "        adata_concat.obs['celltype'] = adata_concat.obs['celltype'].astype('category') \n",
    "\n",
    "        # - cal de genes\n",
    "        rankby_abs = False\n",
    "\n",
    "        sc.tl.rank_genes_groups(\n",
    "            adata_concat,\n",
    "            groupby='batch',\n",
    "            reference='ctrl',\n",
    "            rankby_abs=rankby_abs,\n",
    "            n_genes=len(adata_concat.var),\n",
    "            use_raw=False,\n",
    "            method = 'wilcoxon'\n",
    "        )\n",
    "        de_genes = pd.DataFrame(adata_concat.uns['rank_genes_groups']['names'])\n",
    "        pvals = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals'])\n",
    "        pvals_adj = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals_adj'])\n",
    "        scores = pd.DataFrame(adata_concat.uns['rank_genes_groups']['scores'])\n",
    "        logfoldchanges = pd.DataFrame(adata_concat.uns['rank_genes_groups']['logfoldchanges'])\n",
    "\n",
    "        # - get gene_score\n",
    "        gene_score = pd.DataFrame({'gene':list(de_genes['pert']),\n",
    "                                    'z-score':list(scores['pert'])})\n",
    "\n",
    "        pert_gene_rank_dict[pert] = (list(de_genes['pert']), list(scores['pert']))\n",
    "        \n",
    "        # break\n",
    "        \n",
    "    save_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark_202410/zero_shot/result'\n",
    "    save_prefix = f'{save_prefix_method}/{cell_line_bulk}' # use result of K562 to do the direct transfer\n",
    "    os.makedirs(os.path.join(save_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "    import json\n",
    "    with open(os.path.join(save_dir, save_prefix, 'pert_gene_rank_dict.json'), 'w') as f:\n",
    "        json.dump(pert_gene_rank_dict, f)\n",
    "        \n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    # - get cell line name\n",
    "    common_cell_line = \\\n",
    "    {   'A549': 'A549',\n",
    "        'HEPG2': 'HepG2',\n",
    "        'HT29': 'HT29',\n",
    "        'MCF7': 'MCF7',\n",
    "        # 'SKBR3': 'SK-BR-3',\n",
    "        'SW480': 'SW480',\n",
    "        'PC3': 'PC3',\n",
    "        'A375': 'A375',\n",
    "    } # L1000 cell line : single-cell cell line\n",
    "\n",
    "    # - read adata_L1000, this is processed data\n",
    "    adata_L1000 = sc.read('/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/benchmark_data/L1000/GSE92742/adata_gene_pert.h5ad')\n",
    "\n",
    "\n",
    "    # 使用并行执行\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_cell_line, cell_line_bulk, common_cell_line[cell_line_bulk], common_cell_line, adata_L1000)\n",
    "            for cell_line_bulk in common_cell_line.keys()\n",
    "        ]\n",
    "        \n",
    "        # 等待所有任务完成\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # 获取每个任务的结果，如果有异常，将在此处抛出\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/306 [02:51<7:14:43, 85.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_375545/832459055.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Enter perturbation conditions to simulate signal propagation after the perturbation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     oracle_ctrl.simulate_shift(perturb_condition=goi_dict,\n\u001b[0m\u001b[1;32m     26\u001b[0m                         n_propagation=3)\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# - get the prediction; delta_X = simulated_count - imputed_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdelta_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulated_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moracle_ctrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"delta_X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle_ctrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"simulated_count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/lichen/anaconda3/envs/scGPT/lib/python3.9/site-packages/celloracle/trajectory/oracle_core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, perturb_condition, GRN_unit, n_propagation, ignore_warning, use_randomized_GRN, clip_delta_X)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mHowever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhigher\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpropagation\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mcause\u001b[0m \u001b[0mmore\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mclip_delta_X\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0msimulated\u001b[0m \u001b[0mgene\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0mshift\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mlead\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgene\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0moutside\u001b[0m \u001b[0mof\u001b[0m \u001b[0mWT\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mgene\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mclipped\u001b[0m \u001b[0mto\u001b[0m \u001b[0mWT\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \"\"\"\n\u001b[0;32m--> 694\u001b[0;31m         self.__simulate_shift(perturb_condition=perturb_condition,\n\u001b[0m\u001b[1;32m    695\u001b[0m                                       \u001b[0mGRN_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGRN_unit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                                       \u001b[0mn_propagation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_propagation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                                       \u001b[0mignore_warning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_warning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/lichen/anaconda3/envs/scGPT/lib/python3.9/site-packages/celloracle/trajectory/oracle_core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, perturb_condition, GRN_unit, n_propagation, ignore_warning, use_randomized_GRN, n_min, n_max, clip_delta_X)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0mcells_in_the_cluster_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcluster_info\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0msimulation_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcells_in_the_cluster_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                 \u001b[0mgem_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgem_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcells_in_the_cluster_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m                 simulated_in_the_cluster = _do_simulation(\n\u001b[0m\u001b[1;32m    853\u001b[0m                                              \u001b[0mcoef_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                                              \u001b[0msimulation_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimulation_input_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                                              \u001b[0mgem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgem_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/lichen/anaconda3/envs/scGPT/lib/python3.9/site-packages/celloracle/trajectory/oracle_GRN.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(coef_matrix, simulation_input, gem, n_propagation)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdelta_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation_input\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdelta_simulated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_propagation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdelta_simulated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_simulated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mdelta_simulated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelta_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# gene expression cannot be negative. adjust delta values to make sure that gene expression are not netavive values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/lichen/anaconda3/envs/scGPT/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1605\u001b[0m                 )\n\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m             return self._constructor(\n\u001b[0;32m-> 1609\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1610\u001b[0m             )\n\u001b[1;32m   1611\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pert in tqdm(common_perts):\n",
    "    \n",
    "\n",
    "    # - this is for crispra\n",
    "    gois = [pert]\n",
    "    goi_dict = {}\n",
    "\n",
    "    # - all data in L1000 is knockdown\n",
    "    for goi in gois:\n",
    "        # -- if original value is zero\n",
    "        if np.mean(adata_rna[:,goi].X.toarray())==0:\n",
    "            print(f'{goi} ctrl expression is 0')\n",
    "            continue\n",
    "        # -- if the TF has no targets\n",
    "        if goi not in list(tf_GRN_dict.keys()):\n",
    "            print(f'{goi} is not in the tf_GRN_dict, no targets')\n",
    "            continue\n",
    "        goi_dict[goi] = 0\n",
    "    if len(goi_dict) == 0:\n",
    "        print(f'{pert} is filtered')\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Enter perturbation conditions to simulate signal propagation after the perturbation.\n",
    "    oracle_ctrl.simulate_shift(perturb_condition=goi_dict,\n",
    "                        n_propagation=3)\n",
    "    # - get the prediction; delta_X = simulated_count - imputed_count\n",
    "    delta_X, simulated_count = oracle_ctrl.adata.layers[\"delta_X\"], oracle_ctrl.adata.layers[\"simulated_count\"]\n",
    "\n",
    "\n",
    "    # - create adata_pert\n",
    "    adata_pert = adata_rna.copy()\n",
    "    adata_pert.X = simulated_count\n",
    "    adata_pert.X[adata_pert.X < 0] = 0\n",
    "    adata_pert.obs_names = [i+f'_{pert}' for i in adata_pert.obs_names]\n",
    "\n",
    "    # - adata_ctrl\n",
    "    adata_ctrl = adata_rna.copy()\n",
    "\n",
    "    adata_ctrl.obs['batch'] = 'ctrl'\n",
    "    adata_pert.obs['batch'] = 'pert'\n",
    "\n",
    "    adata_concat = ad.concat([adata_ctrl, adata_pert])\n",
    "    adata_concat.obs['batch'] = adata_concat.obs['batch'].astype('category') \n",
    "    adata_concat.obs['celltype'] = adata_concat.obs['celltype'].astype('category') \n",
    "\n",
    "    # - cal de genes\n",
    "    rankby_abs = False\n",
    "\n",
    "    sc.tl.rank_genes_groups(\n",
    "        adata_concat,\n",
    "        groupby='batch',\n",
    "        reference='ctrl',\n",
    "        rankby_abs=rankby_abs,\n",
    "        n_genes=len(adata_concat.var),\n",
    "        use_raw=False,\n",
    "        method = 'wilcoxon'\n",
    "    )\n",
    "    de_genes = pd.DataFrame(adata_concat.uns['rank_genes_groups']['names'])\n",
    "    pvals = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals'])\n",
    "    pvals_adj = pd.DataFrame(adata_concat.uns['rank_genes_groups']['pvals_adj'])\n",
    "    scores = pd.DataFrame(adata_concat.uns['rank_genes_groups']['scores'])\n",
    "    logfoldchanges = pd.DataFrame(adata_concat.uns['rank_genes_groups']['logfoldchanges'])\n",
    "\n",
    "    # - get gene_score\n",
    "    gene_score = pd.DataFrame({'gene':list(de_genes['pert']),\n",
    "                                'z-score':list(scores['pert'])})\n",
    "\n",
    "    pert_gene_rank_dict[pert] = (list(de_genes['pert']), list(scores['pert']))\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(\n",
    "    adata_concat,\n",
    "    groupby='batch',\n",
    "    reference='ctrl',\n",
    "    rankby_abs=rankby_abs,\n",
    "    n_genes=len(adata_concat.var),\n",
    "    use_raw=False,\n",
    "    method = 'wilcoxon'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
