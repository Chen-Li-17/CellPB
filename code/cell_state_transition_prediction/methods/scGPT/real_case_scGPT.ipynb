{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env: scGPT_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/data1/lichen/code/single_cell_perturbation/others/scGPT/\")\n",
    "\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerGenerator\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    criterion_neg_log_bernoulli,\n",
    "    masked_relative_error,\n",
    ")\n",
    "from scgpt.tokenizer import tokenize_batch, pad_batch, tokenize_and_pad_batch\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.utils import set_seed, map_raw_id_to_vocab_id\n",
    "\n",
    "# matplotlib.rcParams[\"savefig.transparent\"] = False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from gears import PertData, GEARS\n",
    "from gears.inference import compute_metrics, deeper_analysis, non_dropout_analysis\n",
    "from gears.utils import create_cell_graph_dataset_for_prediction\n",
    "\n",
    "import importlib\n",
    "from scperturb import *\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/data1/lichen/code/single_cell_perturbation/scPerturb/Byte_Pert_Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v1\n",
    "from v1.utils import *\n",
    "from v1.dataloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pert_dict = {\n",
    "    'CAR_T': ['PDCD1'],\n",
    "    'blood': ['GATA1', 'SPI1'],\n",
    "    'OSKM': [['SOX2',\n",
    "         'POU5F1',\n",
    "         'KLF4',\n",
    "         'MYC']],\n",
    "    'ADM': ['PTF1A']\n",
    "}\n",
    "dataset_celltype_dict = {\n",
    "    'CAR_T': 'Tex', \n",
    "    'blood': 'LMPP',\n",
    "    'OSKM': 'Fibroblast-like',\n",
    "    'ADM': 'Acinar'\n",
    "}\n",
    "\n",
    "dataset_dire_dict = {\n",
    "    'CAR_T': 'down', \n",
    "    'blood': 'down',\n",
    "    'OSKM': 'up',\n",
    "    'ADM': 'down'\n",
    "}\n",
    "\n",
    "\n",
    "datasets = list(dataset_pert_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the token is : 60697\n"
     ]
    }
   ],
   "source": [
    "#=========================basic parameters\n",
    "\n",
    "# - init scGPT para\n",
    "# settings for data prcocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "pad_value = 0  # for padding values\n",
    "pert_pad_id = 2\n",
    "\n",
    "n_hvg = 0  # number of highly variable genes\n",
    "include_zero_gene = \"all\"  # include zero expr genes in training input, \"all\", \"batch-wise\", \"row-wise\", or False\n",
    "# max_seq_len = 1536\n",
    "max_seq_len = 6000\n",
    "\n",
    "\n",
    "# settings for training\n",
    "MLM = True  # whether to use masked language modeling, currently it is always on.\n",
    "CLS = False  # celltype classification objective\n",
    "CCE = False  # Contrastive cell embedding objective\n",
    "MVC = False  # Masked value prediction for cell embedding\n",
    "ECS = False  # Elastic cell similarity objective\n",
    "cell_emb_style = \"cls\"\n",
    "mvc_decoder_style = \"inner product, detach\"\n",
    "amp = True\n",
    "load_model = \"/data1/lichen/code/single_cell_perturbation/others/scGPT/save/scGPT_human\"\n",
    "\n",
    "load_param_prefixs = [\n",
    "    \"encoder\",\n",
    "    \"value_encoder\",\n",
    "    \"transformer_encoder\",\n",
    "]\n",
    "\n",
    "# settings for optimizer\n",
    "lr = 1e-4  # or 1e-4\n",
    "batch_size = 64\n",
    "eval_batch_size = 64\n",
    "epochs = 15\n",
    "schedule_interval = 1\n",
    "early_stop = 5\n",
    "\n",
    "# settings for the model\n",
    "embsize = 512  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 12  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 8  # number of heads in nn.MultiheadAttention\n",
    "n_layers_cls = 3\n",
    "dropout = 0.2  # dropout probability\n",
    "use_fast_transformer = True  # whether to use fast transformer\n",
    "\n",
    "# logging\n",
    "log_interval = 100\n",
    "\n",
    "# dataset and evaluation choices\n",
    "data_name = \"adamson\"\n",
    "split = \"simulation\"\n",
    "if data_name == \"norman\":\n",
    "    perts_to_plot = [\"SAMD1+ZBTB1\"]\n",
    "elif data_name == \"adamson\":\n",
    "    perts_to_plot = [\"KCTD16+ctrl\"]\n",
    "\n",
    "# - 恢复默认参数\n",
    "# plt.rcdefaults()\n",
    "\n",
    "#==========================set GPU\n",
    "# - multi gpu para\n",
    "n_gpu = 3\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_ids = [\n",
    "                # 0,\n",
    "               1, \n",
    "               # 2, \n",
    "               # 3,\n",
    "               ]\n",
    "\n",
    "# - training epoch\n",
    "epochs = 20\n",
    "max_seq_len = 6000\n",
    "early_stop = 20\n",
    "save_flag = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#===========================set vocab\n",
    "# - get the model \n",
    "model_dir = Path(load_model)\n",
    "\n",
    "\n",
    "# - get the vocab\n",
    "model_config_file = model_dir / \"args.json\"\n",
    "model_file = model_dir / \"best_model.pt\"\n",
    "vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "\n",
    "# token2idx = json.load(vocab_file)\n",
    "with vocab_file.open(\"r\") as f:\n",
    "    token2idx = json.load(f)\n",
    "print('length of the token is :',len(token2idx))\n",
    "\n",
    "\n",
    "# - add token to the vocab\n",
    "for s in special_tokens:\n",
    "    if s not in vocab:\n",
    "        vocab.append_token(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model from /nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/down/model_best.pt, the model args will override the config /data1/lichen/code/single_cell_perturbation/others/scGPT/save/scGPT_human/args.json.\n",
      "Using simple batchnorm instead of domain specific batchnorm\n"
     ]
    }
   ],
   "source": [
    "#=====================================load scGPT model\n",
    "# - load the model\n",
    "with open(model_config_file, \"r\") as f:\n",
    "    model_configs = json.load(f)\n",
    "print(\n",
    "    f\"Resume model from {model_file}, the model args will override the \"\n",
    "    f\"config {model_config_file}.\"\n",
    ")\n",
    "embsize = model_configs[\"embsize\"]\n",
    "nhead = model_configs[\"nheads\"]\n",
    "d_hid = model_configs[\"d_hid\"]\n",
    "nlayers = model_configs[\"nlayers\"]\n",
    "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "\n",
    "\n",
    "# - intial the model\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerGenerator(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    nlayers_cls=n_layers_cls,\n",
    "    n_cls=1,\n",
    "    vocab=vocab,\n",
    "    dropout=dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    pert_pad_id=pert_pad_id,\n",
    "    do_mvc=MVC,\n",
    "    cell_emb_style=cell_emb_style,\n",
    "    mvc_decoder_style=mvc_decoder_style,\n",
    "    use_fast_transformer=use_fast_transformer,\n",
    ")\n",
    "\n",
    "# - load the model\n",
    "if load_param_prefixs is not None and load_model is not None:\n",
    "\n",
    "    # -- load out weight\n",
    "    # model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/down/model_best.pt'\n",
    "    model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/up/model_best.pt'\n",
    "    # model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain_initial/down/model_best.pt'\n",
    "\n",
    "    # 加载保存的模型权重\n",
    "    saved_state_dict = torch.load(model_file)\n",
    "    from collections import OrderedDict\n",
    "    # 创建一个新的字典来存储修改后的权重\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    # 修改键名称\n",
    "    for key, value in saved_state_dict.items():\n",
    "        new_key = key.replace('module.', '')  # 移除'module.'前缀\n",
    "        new_state_dict[new_key] = value\n",
    "\n",
    "    # 加载修改后的权重\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "# - add the parallel\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "# - put model on device\n",
    "model.to(device)\n",
    "\n",
    "best_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scGPT跑所有datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== blood ====================\n",
      "match 1205/1206 genes in vocabulary of size 60697.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** GATA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:27<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets[:]:\n",
    "    # dataset = 'OSKM'\n",
    "    dataset = 'blood'\n",
    "    print('='*20, dataset, '='*20)\n",
    "    save_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/real_case/data'\n",
    "    adata_rna = sc.read(os.path.join(save_dir, dataset, 'adata_ctrl.h5ad'))\n",
    "    if not isinstance(adata_rna.X, np.ndarray):\n",
    "        adata_rna.X = adata_rna.X.toarray()\n",
    "    adata = adata_rna.copy()\n",
    "\n",
    "    # - init adata\n",
    "    adata_rna.var[\"gene_name\"] = list(adata_rna.var_names)\n",
    "    adata_rna.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata_rna.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata_rna.var[\"id_in_vocab\"])\n",
    "    print(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    genes = adata_rna.var[\"gene_name\"].tolist()\n",
    "\n",
    "    # - get token of input genes\n",
    "    vocab.set_default_index(vocab[\"<pad>\"])\n",
    "    gene_ids = np.array(\n",
    "        [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
    "    )\n",
    "    n_genes = len(genes)\n",
    "\n",
    "    for pert in tqdm(dataset_pert_dict[dataset]):\n",
    "        # pert = ['SOX2','POU5F1','KLF4','MYC']\n",
    "        print('*'*20, pert)\n",
    "        # - use for multiple perts\n",
    "        if isinstance(pert, str):\n",
    "            pert_combo = [pert]\n",
    "        else:\n",
    "            pert_combo = pert\n",
    "        # - prepare the test_loader\n",
    "        Xs = adata_rna.X\n",
    "        var_names = list(adata_rna.var_names)\n",
    "\n",
    "        cell_graphs = []\n",
    "        for X in Xs:\n",
    "            # - pert_flags for multi perts\n",
    "            pert_flags = torch.zeros(Xs.shape[1])\n",
    "            for tmp_pert in pert_combo:\n",
    "                if tmp_pert not in var_names:\n",
    "                    continue\n",
    "                else:\n",
    "                    pert_flags[var_names.index(tmp_pert)] = 1\n",
    "            tmp_Data = Data(x=torch.Tensor(X.reshape(1,-1)),\n",
    "                        pert_flags=pert_flags.reshape(1,-1))\n",
    "            cell_graphs.append(tmp_Data)\n",
    "\n",
    "        test_loader = DataLoader(cell_graphs,\n",
    "                                batch_size=32, shuffle=False)\n",
    "\n",
    "        pred = []\n",
    "        for itr, batch in enumerate(test_loader):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                p = pred_perturb_new(best_model, batch, include_zero_gene, gene_ids=gene_ids)\n",
    "                pred.extend(p.cpu())\n",
    "        pred = torch.stack(pred)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "\n",
    "        pert_prefix = '_'.join(pert_combo)\n",
    "        # - create adata_pert\n",
    "        adata_pert = adata_rna.copy()\n",
    "        adata_pert.X = pred\n",
    "        adata_pert.obs_names = [i+f'_{pert_prefix}' for i in adata_pert.obs_names]\n",
    "\n",
    "        # - adata_ctrl\n",
    "        adata_ctrl = adata_rna.copy()\n",
    "\n",
    "        # tmp_dir = f'/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/real_case/data/{dataset}'\n",
    "        tmp_dir = f'/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark_202410/real_case/result/{dataset}'\n",
    "        save_prefix = f'scGPT/{pert_prefix}' # use result of K562 to do the direct transfer\n",
    "        os.makedirs(os.path.join(tmp_dir, save_prefix), exist_ok=True)\n",
    "        adata_pert.write(os.path.join(tmp_dir, save_prefix, 'adata_pert.h5ad'))\n",
    "\n",
    "        break\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scGPT跑所有datasets - 使用minus计算出来delta，然后尝试绘制transition score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== CAR_T ====================\n",
      "match 2548/2647 genes in vocabulary of size 60697.\n",
      "Using simple batchnorm instead of domain specific batchnorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** PDCD1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== blood ====================\n",
      "match 1205/1206 genes in vocabulary of size 60697.\n",
      "Using simple batchnorm instead of domain specific batchnorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** GATA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:28<00:28, 28.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** SPI1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:56<00:00, 28.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== OSKM ====================\n",
      "match 3137/3563 genes in vocabulary of size 60697.\n",
      "Using simple batchnorm instead of domain specific batchnorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** ['SOX2', 'POU5F1', 'KLF4', 'MYC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:38<00:00, 98.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== ADM ====================\n",
      "match 4511/4880 genes in vocabulary of size 60697.\n",
      "Using simple batchnorm instead of domain specific batchnorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** PTF1A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.29s/it]\n"
     ]
    }
   ],
   "source": [
    "adata_mode = 'non_minus'\n",
    "# minus: save adata as the minus delta\n",
    "# non_minus: save adata, add the minus delta on the original gene exp\n",
    "\n",
    "for dataset in datasets[:]:\n",
    "    # dataset = 'OSKM'\n",
    "    # dataset = 'blood'\n",
    "    # dataset = 'CAR_T'\n",
    "    print('='*20, dataset, '='*20)\n",
    "    save_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/real_case/data'\n",
    "    adata_rna = sc.read(os.path.join(save_dir, dataset, 'adata_ctrl_v2.h5ad'))\n",
    "    if not isinstance(adata_rna.X, np.ndarray):\n",
    "        adata_rna.X = adata_rna.X.toarray()\n",
    "    adata = adata_rna.copy()\n",
    "\n",
    "    # - init adata\n",
    "    adata_rna.var[\"gene_name\"] = list(adata_rna.var_names)\n",
    "    adata_rna.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata_rna.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata_rna.var[\"id_in_vocab\"])\n",
    "    print(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    genes = adata_rna.var[\"gene_name\"].tolist()\n",
    "\n",
    "    # - get token of input genes\n",
    "    vocab.set_default_index(vocab[\"<pad>\"])\n",
    "    gene_ids = np.array(\n",
    "        [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
    "    )\n",
    "    n_genes = len(genes)\n",
    "\n",
    "\n",
    "    #################################################### load model, OSKM for up model\n",
    "    model = TransformerGenerator(\n",
    "        ntokens,\n",
    "        embsize,\n",
    "        nhead,\n",
    "        d_hid,\n",
    "        nlayers,\n",
    "        nlayers_cls=n_layers_cls,\n",
    "        n_cls=1,\n",
    "        vocab=vocab,\n",
    "        dropout=dropout,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        pert_pad_id=pert_pad_id,\n",
    "        do_mvc=MVC,\n",
    "        cell_emb_style=cell_emb_style,\n",
    "        mvc_decoder_style=mvc_decoder_style,\n",
    "        use_fast_transformer=use_fast_transformer,\n",
    "    )\n",
    "    # - load the model\n",
    "    if load_param_prefixs is not None and load_model is not None:\n",
    "\n",
    "        # -- load out weight\n",
    "        # model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/down/model_best.pt'\n",
    "        # model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/up/model_best.pt'\n",
    "        # model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain_initial/down/model_best.pt'\n",
    "\n",
    "        if dataset_dire_dict[dataset] == 'down':\n",
    "            model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/down/model_best.pt'\n",
    "        if dataset_dire_dict[dataset] == 'up':\n",
    "            model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scGPT_pretrain/up/model_best.pt'\n",
    "\n",
    "\n",
    "\n",
    "        # 加载保存的模型权重\n",
    "        saved_state_dict = torch.load(model_file)\n",
    "        from collections import OrderedDict\n",
    "        # 创建一个新的字典来存储修改后的权重\n",
    "        new_state_dict = OrderedDict()\n",
    "\n",
    "        # 修改键名称\n",
    "        for key, value in saved_state_dict.items():\n",
    "            new_key = key.replace('module.', '')  # 移除'module.'前缀\n",
    "            new_state_dict[new_key] = value\n",
    "\n",
    "        # 加载修改后的权重\n",
    "        model.load_state_dict(new_state_dict)\n",
    "\n",
    "    # - add the parallel\n",
    "    model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "    # - put model on device\n",
    "    model.to(device)\n",
    "\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    #################################################### run the inference\n",
    "    for pert in tqdm(dataset_pert_dict[dataset]):\n",
    "        # pert = 'GATA1'\n",
    "        # pert = ['SOX2','POU5F1','KLF4','MYC']\n",
    "        # pert = 'SPI1'\n",
    "        # pert = 'PDCD1'\n",
    "        print('*'*20, pert)\n",
    "        # - use for multiple perts\n",
    "        if isinstance(pert, str):\n",
    "            pert_combo = [pert]\n",
    "        else:\n",
    "            pert_combo = pert\n",
    "        # - prepare the test_loader\n",
    "        Xs = adata_rna.X\n",
    "        var_names = list(adata_rna.var_names)\n",
    "\n",
    "        #================================= get ctrl output\n",
    "        cell_graphs = []\n",
    "        for X in Xs:\n",
    "            # - pert_flags for multi perts\n",
    "            pert_flags = torch.zeros(Xs.shape[1])\n",
    "            for tmp_pert in pert_combo:\n",
    "                if tmp_pert not in var_names:\n",
    "                    continue\n",
    "                else:\n",
    "                    pert_flags[var_names.index(tmp_pert)] = 0\n",
    "            tmp_Data = Data(x=torch.Tensor(X.reshape(1,-1)),\n",
    "                        pert_flags=pert_flags.reshape(1,-1))\n",
    "            cell_graphs.append(tmp_Data)\n",
    "\n",
    "        test_loader = DataLoader(cell_graphs,\n",
    "                                batch_size=32, shuffle=False)\n",
    "\n",
    "        pred = []\n",
    "        for itr, batch in enumerate(test_loader):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                p = pred_perturb_new(best_model, batch, include_zero_gene, gene_ids=gene_ids)\n",
    "                pred.extend(p.cpu())\n",
    "        pred = torch.stack(pred)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_ctrl = pred.copy()\n",
    "\n",
    "        #================================= get pert output\n",
    "        cell_graphs = []\n",
    "        for X in Xs:\n",
    "            # - pert_flags for multi perts\n",
    "            pert_flags = torch.zeros(Xs.shape[1])\n",
    "            for tmp_pert in pert_combo:\n",
    "                if tmp_pert not in var_names:\n",
    "                    continue\n",
    "                else:\n",
    "                    pert_flags[var_names.index(tmp_pert)] = 1\n",
    "            tmp_Data = Data(x=torch.Tensor(X.reshape(1,-1)),\n",
    "                        pert_flags=pert_flags.reshape(1,-1))\n",
    "            cell_graphs.append(tmp_Data)\n",
    "\n",
    "        test_loader = DataLoader(cell_graphs,\n",
    "                                batch_size=32, shuffle=False)\n",
    "\n",
    "        pred = []\n",
    "        for itr, batch in enumerate(test_loader):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                p = pred_perturb_new(best_model, batch, include_zero_gene, gene_ids=gene_ids)\n",
    "                pred.extend(p.cpu())\n",
    "        pred = torch.stack(pred)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_pert = pred.copy()\n",
    "\n",
    "        pert_prefix = '_'.join(pert_combo)\n",
    "\n",
    "        tmp_dir = f'/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark_202410/real_case/result/{dataset}'\n",
    "        save_prefix = f'scGPT/{pert_prefix}' # use result of K562 to do the direct transfer\n",
    "        os.makedirs(os.path.join(tmp_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "\n",
    "        adata_pert = adata_rna.copy()\n",
    "\n",
    "        if adata_mode == 'minus':\n",
    "            adata_pert.X = pred_pert - pred_ctrl\n",
    "            adata_pert.obs_names = [i+f'_{pert_prefix}' for i in adata_pert.obs_names]\n",
    "            adata_pert.write(os.path.join(tmp_dir, save_prefix, 'adata_pert_minus.h5ad'))\n",
    "\n",
    "        elif adata_mode == 'non_minus':\n",
    "            adata_pert.X += pred_pert - pred_ctrl\n",
    "            adata_pert.obs_names = [i+f'_{pert_prefix}' for i in adata_pert.obs_names]\n",
    "            adata_pert.write(os.path.join(tmp_dir, save_prefix, 'adata_pert.h5ad'))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    #     break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pert = adata_rna.copy()\n",
    "\n",
    "# if adata_mode == 'minus':\n",
    "adata_pert.X = pred_pert - pred_ctrl\n",
    "adata_pert.obs_names = [i+f'_{pert_prefix}' for i in adata_pert.obs_names]\n",
    "adata_pert.write(os.path.join(tmp_dir, save_prefix, 'adata_pert_minus.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.95647061e-01,  6.59179688e-03,  5.61523438e-03, ...,\n",
       "         6.91984951e-01,  7.67424405e-01, -3.66210938e-04],\n",
       "       [ 1.27201176e+00,  6.10351562e-03,  5.85937500e-03, ...,\n",
       "         8.19480658e-01,  1.33963871e+00,  1.58691406e-03],\n",
       "       [-2.92968750e-03,  5.85937500e-03,  4.88281250e-03, ...,\n",
       "         1.22070312e-03,  1.31645989e+00,  1.04463267e+00],\n",
       "       ...,\n",
       "       [-1.46484375e-03,  6.83593750e-03,  5.37109375e-03, ...,\n",
       "         2.19726562e-03,  3.84730864e+00,  1.95312500e-03],\n",
       "       [ 6.02443039e-01,  6.34765625e-03,  4.63867188e-03, ...,\n",
       "         7.32421875e-04,  2.88891983e+00,  1.95312500e-03],\n",
       "       [-3.66210938e-03,  6.59179688e-03,  5.12695312e-03, ...,\n",
       "         7.32421875e-04,  1.27215433e+00,  8.54492188e-04]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_pert.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00439453,  0.0065918 ,  0.00561523, ...,  0.00073242,\n",
       "         0.07617188, -0.00036621],\n",
       "       [ 0.00952148,  0.00610352,  0.00585938, ...,  0.00097656,\n",
       "         0.07714844,  0.00158691],\n",
       "       [-0.00292969,  0.00585938,  0.00488281, ...,  0.0012207 ,\n",
       "         0.07714844,  0.00085449],\n",
       "       ...,\n",
       "       [-0.00146484,  0.00683594,  0.00537109, ...,  0.00219727,\n",
       "         0.10546875,  0.00195312],\n",
       "       [ 0.00610352,  0.00634766,  0.00463867, ...,  0.00073242,\n",
       "         0.0859375 ,  0.00195312],\n",
       "       [-0.00366211,  0.0065918 ,  0.00512695, ...,  0.00073242,\n",
       "         0.07617188,  0.00085449]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pert - pred_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69125253, 0.        , 0.        , ..., 0.69125253, 0.69125253,\n",
       "        0.        ],\n",
       "       [1.26249027, 0.        , 0.        , ..., 0.8185041 , 1.26249027,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.23931146,\n",
       "        1.04377818],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 3.74183989,\n",
       "        0.        ],\n",
       "       [0.59633952, 0.        , 0.        , ..., 0.        , 2.80298233,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.19598246,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00439453,  0.0065918 ,  0.00561523, ...,  0.00073242,\n",
       "         0.07617188, -0.00036621],\n",
       "       [ 0.00952148,  0.00610352,  0.00585938, ...,  0.00097656,\n",
       "         0.07714844,  0.00158691],\n",
       "       [-0.00292969,  0.00585938,  0.00488281, ...,  0.0012207 ,\n",
       "         0.07714844,  0.00085449],\n",
       "       ...,\n",
       "       [-0.00146484,  0.00683594,  0.00537109, ...,  0.00219727,\n",
       "         0.10546875,  0.00195312],\n",
       "       [ 0.00610352,  0.00634766,  0.00463867, ...,  0.00073242,\n",
       "         0.0859375 ,  0.00195312],\n",
       "       [-0.00366211,  0.0065918 ,  0.00512695, ...,  0.00073242,\n",
       "         0.07617188,  0.00085449]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_pert.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 7073 × 1206\n",
       "    obs: 'cid', 'seq_tech', 'donor_ID', 'donor_gender', 'donor_age', 'donor_status', 'original_name', 'organ', 'region', 'subregion', 'sample_status', 'treatment', 'ethnicity', 'cell_type', 'cell_id', 'study_id', 'age_bin', 'celltype', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
       "    var: 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'gene_name', 'id_in_vocab'\n",
       "    uns: 'hvg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_perturb_new(\n",
    "    model,\n",
    "    batch_data,\n",
    "    include_zero_gene=\"batch-wise\",\n",
    "    gene_ids=None,\n",
    "    amp=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch_data: a dictionary of input data with keys.\n",
    "\n",
    "    Returns:\n",
    "        output Tensor of shape [N, seq_len]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    batch_data.to(device)\n",
    "    batch_size = len(batch_data.x)\n",
    "    x: torch.Tensor = batch_data.x\n",
    "    # ori_gene_values = x[:, 0].view(batch_size, n_genes)\n",
    "    ori_gene_values = x\n",
    "    # pert_flags = x[:, 1].long().view(batch_size, n_genes)\n",
    "    pert_flags = batch_data.pert_flags.long()\n",
    "\n",
    "    if include_zero_gene in [\"all\", \"batch-wise\"]:\n",
    "        assert gene_ids is not None\n",
    "        if include_zero_gene == \"all\":\n",
    "            input_gene_ids = torch.arange(ori_gene_values.size(1), device=device)\n",
    "        else:  # batch-wise\n",
    "            input_gene_ids = (\n",
    "                ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n",
    "            )\n",
    "        input_values = ori_gene_values[:, input_gene_ids]\n",
    "        input_pert_flags = pert_flags[:, input_gene_ids]\n",
    "\n",
    "        mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n",
    "        mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n",
    "\n",
    "        src_key_padding_mask = torch.zeros_like(\n",
    "            input_values, dtype=torch.bool, device=device\n",
    "        )\n",
    "        with torch.cuda.amp.autocast(enabled=amp):\n",
    "            output_dict = model(\n",
    "                mapped_input_gene_ids,\n",
    "                input_values,\n",
    "                input_pert_flags,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                CLS=False,\n",
    "                CCE=False,\n",
    "                MVC=False,\n",
    "                ECS=False,\n",
    "                do_sample=True,\n",
    "            )\n",
    "        output_values = output_dict[\"mlm_output\"].float()\n",
    "        pred_gene_values = torch.zeros_like(ori_gene_values)\n",
    "        pred_gene_values[:, input_gene_ids] = output_values\n",
    "    return pred_gene_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scGPT_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
