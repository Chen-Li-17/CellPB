{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ import\n",
    "\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "from types import MethodType\n",
    "\n",
    "import importlib\n",
    "from scperturb import *\n",
    "import anndata as ad\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "from gears import PertData, GEARS\n",
    "from gears.inference import compute_metrics, non_dropout_analysis\n",
    "\n",
    "sys.path.insert(0, \"/data1/lichen/code/single_cell_perturbation/others/scGPT/\")\n",
    "sys.path.append(\"/data1/lichen/code/single_cell_perturbation/scPerturb/Byte_Pert_Data/\")\n",
    "\n",
    "import scgpt as scg\n",
    "# from scgpt.model import TransformerGenerator\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    # criterion_neg_log_bernoulli,\n",
    "    masked_relative_error,\n",
    ")\n",
    "\n",
    "import v1\n",
    "from v1.utils import *\n",
    "from v1.dataloader import *\n",
    "\n",
    "# importlib.reload(v1)\n",
    "# importlib.reload(v1.utils)  \n",
    "# importlib.reload(v1.dataloader)\n",
    "\n",
    "\n",
    "from config import prefix_list\n",
    "\n",
    "from torch import nn\n",
    "sys.path.append(\"/data1/lichen/code/single_cell_perturbation/others/scFoundation-main/model/\") # path to this folder\n",
    "from load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ function\n",
    "\n",
    "class scF_finetune_model(nn.Module):\n",
    "\n",
    "    def __init__(self, ckpt_path,frozenmore=True):\n",
    "        super().__init__()\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.frozenmore = frozenmore\n",
    "\n",
    "    def build(self,\n",
    "              pert_pad_id = 2):\n",
    "        model,model_config = load_model_frommmf(self.ckpt_path)\n",
    "        self.token_emb = model.token_emb\n",
    "        self.pos_emb = model.pos_emb\n",
    "        self.encoder = model.encoder\n",
    "\n",
    "        self.pert_emb = nn.Embedding(3, model_config['encoder']['hidden_dim'], padding_idx=pert_pad_id)\n",
    "        \n",
    "        if self.frozenmore:\n",
    "            for _,p in self.token_emb.named_parameters():\n",
    "                p.requires_grad = False\n",
    "            for _,p in self.pos_emb.named_parameters():\n",
    "                p.requires_grad = False\n",
    "            print('self.pos_emb and self.token_emb also frozen')\n",
    "        \n",
    "            for na, param in self.encoder.named_parameters():\n",
    "                param.requires_grad = False\n",
    "            for na, param in self.encoder.transformer_encoder[-2].named_parameters():\n",
    "                print('self.encoder.transformer_encoder ',na,' have grad')\n",
    "                param.requires_grad = True\n",
    "\n",
    "        else:\n",
    "            # - make all the layers able to train\n",
    "            None\n",
    "\n",
    "        self.fc = nn.Linear(model_config['encoder']['hidden_dim'], 1)\n",
    "        self.fc1 = nn.Sequential(\n",
    "        nn.Linear(model_config['encoder']['hidden_dim'], 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 10)  # ['n_class']\n",
    "        ) \n",
    "        self.norm = torch.nn.BatchNorm1d(model_config['encoder']['hidden_dim'], affine=False, eps=1e-6)\n",
    "        self.model_config = model_config\n",
    "        \n",
    "    def forward(self, \n",
    "                ori_gene_values,\n",
    "                pert_flags,\n",
    "                position_gene_ids,\n",
    "                *args, **kwargs):\n",
    "        \n",
    "        x = ori_gene_values\n",
    "        value_labels = torch.ones_like(\n",
    "            x, dtype=torch.bool\n",
    "        )\n",
    "\n",
    "        x_padding = x.eq(self.model_config['pad_token_id'])\n",
    "        x = self.token_emb(torch.unsqueeze(x, 2).float(), output_weight = 0)\n",
    "\n",
    "        # position_gene_ids = position_gene_ids.reshape(-1, 1).repeat(x.shape, 1)\n",
    "        position_emb = self.pos_emb(position_gene_ids)\n",
    "        x += position_emb\n",
    "\n",
    "        x += self.pert_emb(pert_flags)\n",
    "\n",
    "        logits = self.encoder(x, x_padding)\n",
    "\n",
    "        logits = self.fc(logits)\n",
    "        logits = logits.squeeze(-1)\n",
    "\n",
    "        # # mlp\n",
    "        # logits, _ = torch.max(logits, dim=1)  # b,dim\n",
    "\n",
    "        # logits = self.norm(logits)\n",
    "        # logits = self.fc1(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "def pred_perturb_new(\n",
    "    model,\n",
    "    batch_data,\n",
    "    # include_zero_gene=\"batch-wise\",\n",
    "    # gene_ids=None,\n",
    "    amp=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch_data: a dictionary of input data with keys.\n",
    "\n",
    "    Returns:\n",
    "        output Tensor of shape [N, seq_len]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    batch_data.to(device)\n",
    "    \n",
    "    input_values = batch_data.x\n",
    "    pert_flags = batch_data.pert_flags.long()\n",
    "    mapped_input_gene_ids = batch_data.mapped_input_gene_ids\n",
    "\n",
    "\n",
    "    with torch.cuda.amp.autocast(enabled=amp):\n",
    "        output_values = model(\n",
    "            input_values,\n",
    "            pert_flags,\n",
    "            mapped_input_gene_ids\n",
    "        )\n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ init para\n",
    "# init para\n",
    "\n",
    "# - init dataloader para\n",
    "data_dir = '/nfs/public/lichen/data/single_cell/perturb_data/scPerturb/raw/scPerturb_rna/statistic_20240520'\n",
    "pert_cell_filter = 100 # this is used to filter perts, cell number less than this will be filtered\n",
    "seed = 2024 # this is the random seed\n",
    "split_type = 1 # 1 for unseen perts; 0 for unseen celltypes\n",
    "split_ratio = [0.7, 0.2, 0.1] # train:test:val; val is used to choose data, test is for final validation\n",
    "var_num = 5000 # selecting hvg number\n",
    "num_de_genes = 20 # number of de genes\n",
    "# bs_train = 2 # batch size of trainloader\n",
    "bs_test =  2 # batch size of testloader\n",
    "lr = 1e-4\n",
    "\n",
    "# - multi gpu para\n",
    "n_gpu = 1\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device_ids = list(range(n_gpu))\n",
    "device_ids = [3]\n",
    "\n",
    "# - training epoch\n",
    "epochs = 20\n",
    "max_seq_len = 6000\n",
    "early_stop = 20\n",
    "save_flag = True\n",
    "\n",
    "# - intial the loss para\n",
    "amp = True\n",
    "schedule_interval = 1\n",
    "lr = 1e-4\n",
    "include_zero_gene = \"all\"\n",
    "log_interval = 100\n",
    "mask_value = -1\n",
    "\n",
    "\n",
    "gene_mode = 'whole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pert_dict = {\n",
    "    'CAR_T': ['PDCD1'],\n",
    "    'blood': ['GATA1', 'SPI1'],\n",
    "    'OSKM': [['SOX2',\n",
    "         'POU5F1',\n",
    "         'KLF4',\n",
    "         'MYC']],\n",
    "    'ADM': ['PTF1A']\n",
    "}\n",
    "dataset_celltype_dict = {\n",
    "    'CAR_T': 'Tex', \n",
    "    'blood': 'LMPP',\n",
    "    'OSKM': 'Fibroblast-like',\n",
    "    'ADM': 'Acinar'\n",
    "}\n",
    "\n",
    "\n",
    "dataset_dire_dict = {\n",
    "    'CAR_T': 'down', \n",
    "    'blood': 'down',\n",
    "    'OSKM': 'up',\n",
    "    'ADM': 'down'\n",
    "}\n",
    "\n",
    "\n",
    "datasets = list(dataset_pert_dict.keys())\n",
    "\n",
    "# dataset = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== CAR_T ====================\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common genes are:  2376\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** PDCD1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 1/1 [01:38<00:00, 98.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== blood ====================\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common genes are:  1143\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** GATA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      " 50%|█████     | 1/2 [02:29<02:29, 149.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** SPI1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 2/2 [05:01<00:00, 150.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== OSKM ====================\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common genes are:  2812\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** ['SOX2', 'POU5F1', 'KLF4', 'MYC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 1/1 [13:27<00:00, 807.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== ADM ====================\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common genes are:  4323\n",
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** PTF1A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lichen/software/anaconda3/envs/scFoundation/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 1/1 [02:28<00:00, 148.47s/it]\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"scF apply L1000\")\n",
    "parser.add_argument('--cell_line_bulk', type=str, default=None)\n",
    "parser.add_argument('--model_mode', type=str, default=None) # pretrain, init\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.model_mode = 'pretrain'\n",
    "model_mode = args.model_mode\n",
    "\n",
    "adata_mode = 'non_minus'\n",
    "# minus: save adata as the minus delta\n",
    "# non_minus: save adata, add the minus delta on the original gene exp\n",
    "\n",
    "for dataset in datasets[:]:\n",
    "    # dataset = 'OSKM'\n",
    "    # dataset = 'blood'\n",
    "    # dataset = 'CAR_T'\n",
    "    print('='*20, dataset, '='*20)\n",
    "\n",
    "    ckpt_path = '/data1/lichen/code/single_cell_perturbation/others/scFoundation-main/model/models/models.ckpt'\n",
    "    model,model_config = load_model_frommmf(ckpt_path)\n",
    "\n",
    "    save_dir = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/real_case/data'\n",
    "    adata_rna = sc.read(os.path.join(save_dir, dataset, 'adata_ctrl_v2.h5ad'))\n",
    "    if not isinstance(adata_rna.X, np.ndarray):\n",
    "        adata_rna.X = adata_rna.X.toarray()\n",
    "\n",
    "    #====================get scF common, and mapped gene ids\n",
    "    adata = adata_rna.copy()\n",
    "    X_df= pd.DataFrame(adata.X, index=adata.obs.index.tolist(), columns=adata.var.index.tolist()) # read from csv file\n",
    "    gene_list_df = pd.read_csv('/data1/lichen/code/single_cell_perturbation/others/scFoundation-main/OS_scRNA_gene_index.19264.tsv', header=0, delimiter='\\t')\n",
    "    scF_gene_list = list(gene_list_df['gene_name'])\n",
    "    print('common genes are: ', len(np.intersect1d(scF_gene_list, adata.var_names)))\n",
    "\n",
    "    # - transform our adata to scF adata\n",
    "    from scRNA_workflow import *\n",
    "    X_df, to_fill_columns, var = main_gene_selection(X_df, scF_gene_list)\n",
    "    adata_uni = sc.AnnData(X_df)\n",
    "    adata_uni.obs = adata.obs\n",
    "    adata_uni.uns = adata.uns\n",
    "\n",
    "    if gene_mode == 'common':\n",
    "        # - get common genes\n",
    "        common_genes = np.intersect1d(adata_rna.var_names, adata_uni.var_names)\n",
    "        print('common genes to scF gene list is: ', f'{len(common_genes)}/{len(adata_rna.var_names)}')\n",
    "        # - get the gene_id [common_gene_ids are the input to scF, gene positions]\n",
    "        common_gene_ids = np.array([list(adata_uni.var_names).index(gene) for gene in common_genes])\n",
    "        common_gene_ids = torch.tensor(common_gene_ids)\n",
    "\n",
    "        adata_ctrl = adata_rna[:, common_genes].copy()\n",
    "    elif gene_mode == 'whole':\n",
    "        common_genes = np.array(adata_rna.var_names)\n",
    "        # - get the gene_id [common_gene_ids are the input to scF, gene positions]\n",
    "        common_gene_ids = np.array([list(adata_uni.var_names).index(gene) if gene in adata_uni.var_names else model_config['pad_token_id'] for gene in common_genes])\n",
    "        common_gene_ids = torch.tensor(common_gene_ids)\n",
    "        adata_ctrl = adata_rna.copy()\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "\n",
    "    #====================initial the model\n",
    "    # - initial model\n",
    "    scF_model = scF_finetune_model(ckpt_path=ckpt_path,\n",
    "                                    frozenmore = False)\n",
    "    scF_model.build()\n",
    "\n",
    "    if model_mode == 'pretrain':\n",
    "        # -- load out weight\n",
    "        # model_file = '/hpc-cache-pfs/home/lichen/result/single_cell_perturbation/scFoundation_pretrain/down/model_best.pt'\n",
    "\n",
    "        if dataset_dire_dict[dataset] == 'down':\n",
    "            model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scFoundation_pretrain_v5/down/model_best.pt'\n",
    "        if dataset_dire_dict[dataset] == 'up':\n",
    "            model_file = '/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark/volc_result/scFoundation_pretrain_v5/up/model_best.pt'\n",
    "        # 加载保存的模型权重\n",
    "        saved_state_dict = torch.load(model_file)\n",
    "        from collections import OrderedDict\n",
    "        # 创建一个新的字典来存储修改后的权重\n",
    "        new_state_dict = OrderedDict()\n",
    "        # 修改键名称\n",
    "        for key, value in saved_state_dict.items():\n",
    "            new_key = key.replace('module.', '')  # 移除'module.'前缀\n",
    "            new_state_dict[new_key] = value\n",
    "        # 加载修改后的权重\n",
    "        scF_model.load_state_dict(new_state_dict)\n",
    "\n",
    "    elif model_mode == 'init':\n",
    "        None\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    # - add the parallel\n",
    "    model = torch.nn.DataParallel(scF_model, device_ids=device_ids)\n",
    "    # - put model on device\n",
    "    model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    for pert in tqdm(dataset_pert_dict[dataset]):\n",
    "\n",
    "        # pert = 'SPI1'\n",
    "        print('*'*20, pert)\n",
    "\n",
    "        if isinstance(pert, str):\n",
    "            pert_combo = [pert]\n",
    "        else:\n",
    "            pert_combo = pert\n",
    "\n",
    "        # - prepare the test_loader\n",
    "        Xs = adata_ctrl.X\n",
    "        var_names = list(adata_ctrl.var_names)\n",
    "\n",
    "        if not isinstance(Xs, np.ndarray):\n",
    "            Xs = Xs.toarray()\n",
    "\n",
    "        #================================= get ctrl output\n",
    "        cell_graphs = []\n",
    "        for X in Xs:\n",
    "            # - pert_flags for multi perts\n",
    "            pert_flags = torch.zeros(Xs.shape[1])\n",
    "            for tmp_pert in pert_combo:\n",
    "                if tmp_pert not in var_names:\n",
    "                    raise ValueError(f'{pert} not in var_names')\n",
    "                else:\n",
    "                    pert_flags[var_names.index(tmp_pert)] = 0\n",
    "            tmp_Data = Data(x = torch.Tensor(X.reshape(1, -1)),\n",
    "                        pert_flags = pert_flags.reshape(1, -1),\n",
    "                        mapped_input_gene_ids = common_gene_ids.reshape(1, -1))\n",
    "            cell_graphs.append(tmp_Data)\n",
    "\n",
    "        test_loader = DataLoader(cell_graphs,\n",
    "                                batch_size=bs_test * n_gpu, \n",
    "                                shuffle=False)\n",
    "\n",
    "        # - infer the data\n",
    "        pred = []\n",
    "        for itr, batch in enumerate(test_loader):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                p = pred_perturb_new(best_model, batch)\n",
    "                pred.extend(p.cpu())\n",
    "        pred = torch.stack(pred)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_ctrl = pred.copy()\n",
    "\n",
    "        #================================= get pert output\n",
    "        cell_graphs = []\n",
    "        for X in Xs:\n",
    "            # - pert_flags for multi perts\n",
    "            pert_flags = torch.zeros(Xs.shape[1])\n",
    "            for tmp_pert in pert_combo:\n",
    "                if tmp_pert not in var_names:\n",
    "                    raise ValueError(f'{pert} not in var_names')\n",
    "                else:\n",
    "                    pert_flags[var_names.index(tmp_pert)] = 1\n",
    "            tmp_Data = Data(x = torch.Tensor(X.reshape(1, -1)),\n",
    "                        pert_flags = pert_flags.reshape(1, -1),\n",
    "                        mapped_input_gene_ids = common_gene_ids.reshape(1, -1))\n",
    "            cell_graphs.append(tmp_Data)\n",
    "\n",
    "        test_loader = DataLoader(cell_graphs,\n",
    "                                batch_size=bs_test * n_gpu, \n",
    "                                shuffle=False)\n",
    "\n",
    "        # - infer the data\n",
    "        pred = []\n",
    "        for itr, batch in enumerate(test_loader):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                p = pred_perturb_new(best_model, batch)\n",
    "                pred.extend(p.cpu())\n",
    "        pred = torch.stack(pred)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_pert = pred.copy()\n",
    "\n",
    "        pert_prefix = '_'.join(pert_combo)\n",
    "        tmp_dir = f'/nfs/public/lichen/results/single_cell_perturbation/perturbation_benchmark_202410/real_case/result/{dataset}'\n",
    "        save_prefix = f'scFoundation/{pert_prefix}' # use result of K562 to do the direct transfer\n",
    "        os.makedirs(os.path.join(tmp_dir, save_prefix), exist_ok=True)\n",
    "\n",
    "        adata_pert = adata_rna.copy()\n",
    "\n",
    "        if adata_mode == 'minus':\n",
    "            adata_pert.X = pred_pert - pred_ctrl\n",
    "            adata_pert.obs_names = [i+f'_{pert_prefix}' for i in adata_pert.obs_names]\n",
    "            adata_pert.write(os.path.join(tmp_dir, save_prefix, 'adata_pert_minus.h5ad'))\n",
    "\n",
    "        elif adata_mode == 'non_minus':\n",
    "            adata_pert.X += pred_pert - pred_ctrl\n",
    "            adata_pert.obs_names = [i+f'_{pert_prefix}' for i in adata_pert.obs_names]\n",
    "            adata_pert.write(os.path.join(tmp_dir, save_prefix, 'adata_pert.h5ad'))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    #     break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAR_T'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scGPT_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
